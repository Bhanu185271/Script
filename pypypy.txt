import pandas as pd
from pyspark.sql.types import StructType, StructField, StringType
from pyspark.sql import functions as F

# ----------------------------------
# Step 1: Read Excel into Pandas
# ----------------------------------
file_path = "/Workspace/Users/chandrabhanu.x.chandrabhanu@gsk.com/Feedback_Report.xlsx"
df_excel = pd.read_excel(file_path, sheet_name="Feedback Data", nrows=5000)

excel_columns = ["AudioID", "QuestionID", "QuestionText", "ResponseText"]
df_excel = df_excel[excel_columns]

# Define schema
schema = StructType([
    StructField("AudioID", StringType(), True),
    StructField("QuestionID", StringType(), True),
    StructField("QuestionText", StringType(), True),
    StructField("ResponseText", StringType(), True)
])

# Convert Pandas → Spark
spark_excel = spark.createDataFrame(df_excel.astype(str), schema=schema)

# ----------------------------------
# Step 2: Load Tables
# ----------------------------------
llm_output = spark.table("fieldforce_navigator_uat.llm_audio_insights_output")
pre_processed = spark.table("fieldforce_navigator_uat.audio_pre_processed_output")

llm_columns = ["AUDIO_ID", "LOCAL_LANGUAGE_AGREED_ACTIONS", "LOCAL_LANGUAGE_SUMMARY",
               "OVERALL_AREA_OF_INTEREST_INSIGHT", "OVERALL_OBJECTIONS"]
pre_processed_columns = ["AUDIO_ID", "BRAND", "MARKET", "TRANSCRIPT_ID", "REGION"]

llm_data = llm_output.select(llm_columns)
pre_data = pre_processed.select(pre_processed_columns)

# ----------------------------------
# Step 3: Joins
# ----------------------------------
result1 = spark_excel.join(llm_data, spark_excel.AudioID == llm_data.AUDIO_ID, "inner") \
                     .drop(llm_data.AUDIO_ID)

stg_result = result1.join(pre_data, result1.AudioID == pre_data.AUDIO_ID, "inner") \
                    .drop(pre_data.AUDIO_ID)

final_result = stg_result

# ----------------------------------
# Step 4: Flexible Filters
# ----------------------------------
filter_audio_ids = []   # Example: ["81D3EDEF-45E4-45BF-888A-D1536366986D"]
filter_brand = []       # Example: ["BrandA"]
filter_market = []      # Example: ["India"]
filter_region = []      # Example: ["APAC"]

if filter_audio_ids:
    final_result = final_result.filter(F.col("AudioID").isin(filter_audio_ids))

if filter_brand:
    final_result = final_result.filter(F.col("BRAND").isin(filter_brand))

if filter_market:
    final_result = final_result.filter(F.col("MARKET").isin(filter_market))

if filter_region:
    final_result = final_result.filter(F.col("REGION").isin(filter_region))

# ----------------------------------
# Step 5: Column Logic
# ----------------------------------
# Extract last word if '?' present
last_word_col = F.regexp_extract("QuestionText", r"(\w+)\?", 1)

# Build column name:
# - Case 1: If "?" present → QuestionID_lastword
# - Case 2: Else → QuestionID_Comments
concat_col = F.when(F.col("QuestionText").rlike(r"\?"),
                    F.concat_ws("_", F.col("QuestionID"), last_word_col)) \
              .otherwise(F.concat_ws("_", F.col("QuestionID"), F.lit("Comments")))

df_with_concat = final_result.withColumn("concat_col", concat_col)

# ----------------------------------
# Step 6: Pivot
# ----------------------------------
final_pivoted = (
    df_with_concat
    .groupBy("AudioID")
    .pivot("concat_col")
    .agg(F.first("ResponseText"))
)

# Final Output
display(final_pivoted)



















import pandas as pd
from pyspark.sql.types import StructType, StructField, StringType
from pyspark.sql import functions as F

# -------------------------------
# 1. Read Excel into Spark
# -------------------------------
file_path = "/Workspace/Users/chandrabhanu.x.chandrabhanu@gsk.com/Feedback_Report.xlsx"
df_excel = pd.read_excel(file_path, sheet_name="Feedback Data", nrows=5000)

excel_columns = ["AudioID", "QuestionID", "QuestionText", "ResponseText"]
df_excel = df_excel[excel_columns]

schema = StructType([
    StructField("AudioID", StringType(), True),
    StructField("QuestionID", StringType(), True),
    StructField("QuestionText", StringType(), True),
    StructField("ResponseText", StringType(), True)
])

spark_excel = spark.createDataFrame(df_excel.astype(str), schema=schema)

# -------------------------------
# 2. Read Databricks tables
# -------------------------------
llm_output = spark.table("fieldforce_navigator_uat.llm_audio_insights_output")
pre_processed = spark.table("fieldforce_navigator_uat.audio_pre_processed_output")

llm_columns = ["AUDIO_ID", "LOCAL_LANGUAGE_AGREED_ACTIONS", "LOCAL_LANGUAGE_SUMMARY",
               "OVERALL_AREA_OF_INTEREST_INSIGHT", "OVERALL_OBJECTIONS"]
pre_processed_columns = ["AUDIO_ID", "BRAND", "MARKET", "REGION", "TRANSCRIPT_ID"]

llm_data = llm_output.select(llm_columns)
pre_data = pre_processed.select(pre_processed_columns)

# -------------------------------
# 3. Join Excel with tables
# -------------------------------
result1 = spark_excel.join(llm_data, spark_excel.AudioID == llm_data.AUDIO_ID, "inner").drop(llm_data.AUDIO_ID)
stg_result = result1.join(pre_data, result1.AudioID == pre_data.AUDIO_ID, "inner").drop(pre_data.AUDIO_ID)

# -------------------------------
# 4. Flexible Filters
# -------------------------------
filter_audio_ids = [
    # "81D3EDEF-45E4-45BF-888A-D1536366986D",
    # "CCDEBCAF-70C2-41EF-8698-E4E29603359A"
]

filter_brands = [
    # "BrandA", "BrandB"
]

filter_markets = [
    # "India", "China"
]

filter_regions = [
    # "APAC", "EMEA"
]

# Apply filters only if lists are not empty
filtered_df = stg_result
if filter_audio_ids:
    filtered_df = filtered_df.filter(F.col("AudioID").isin(filter_audio_ids))

if filter_brands:
    filtered_df = filtered_df.filter(F.col("BRAND").isin(filter_brands))

if filter_markets:
    filtered_df = filtered_df.filter(F.col("MARKET").isin(filter_markets))

if filter_regions:
    filtered_df = filtered_df.filter(F.col("REGION").isin(filter_regions))

final_result = filtered_df

# -------------------------------
# 5. Extract last word if QuestionText has '?'
# -------------------------------
final_result = final_result.withColumn(
    "LastWord",
    F.when(
        F.col("QuestionText").rlike(r"\?"),
        F.regexp_extract(F.regexp_replace(F.col("QuestionText"), r"\?", ""), r"(\w+)$", 1)
    )
)

# -------------------------------
# 6. Concat QuestionID + LastWord
# -------------------------------
final_result = final_result.withColumn(
    "ConcatCol",
    F.when(F.col("LastWord").isNotNull(), F.concat_ws("_", F.col("QuestionID"), F.col("LastWord")))
)

# -------------------------------
# 7. Pivot/Transpose → one row per AudioID
# -------------------------------
pivot_df = final_result.groupBy("AudioID").pivot("ConcatCol").agg(F.first("ResponseText"))

# -------------------------------
# 8. Bring back metadata
# -------------------------------
meta_cols = ["AudioID", "BRAND", "MARKET", "REGION", "TRANSCRIPT_ID"]
meta_df = final_result.select(meta_cols).dropDuplicates()

final_pivoted = meta_df.join(pivot_df, on="AudioID", how="inner")

# -------------------------------
# 9. Final Output
# -------------------------------
display(final_pivoted)






















import pandas as pd
from pyspark.sql.types import StructType, StructField, StringType
from pyspark.sql import functions as F

# -------------------------------
# 1. Read Excel into Spark
# -------------------------------
file_path = "/Workspace/Users/chandrabhanu.x.chandrabhanu@gsk.com/Feedback_Report.xlsx"
df_excel = pd.read_excel(file_path, sheet_name="Feedback Data", nrows=5000)

excel_columns = ["AudioID", "QuestionID", "QuestionText", "ResponseText"]
df_excel = df_excel[excel_columns]

schema = StructType([
    StructField("AudioID", StringType(), True),
    StructField("QuestionID", StringType(), True),
    StructField("QuestionText", StringType(), True),
    StructField("ResponseText", StringType(), True)
])

spark_excel = spark.createDataFrame(df_excel.astype(str), schema=schema)

# -------------------------------
# 2. Read Databricks tables
# -------------------------------
llm_output = spark.table("fieldforce_navigator_uat.llm_audio_insights_output")
pre_processed = spark.table("fieldforce_navigator_uat.audio_pre_processed_output")

llm_columns = ["AUDIO_ID", "LOCAL_LANGUAGE_AGREED_ACTIONS", "LOCAL_LANGUAGE_SUMMARY",
               "OVERALL_AREA_OF_INTEREST_INSIGHT", "OVERALL_OBJECTIONS"]
pre_processed_columns = ["AUDIO_ID", "BRAND", "MARKET", "TRANSCRIPT_ID"]

llm_data = llm_output.select(llm_columns)
pre_data = pre_processed.select(pre_processed_columns)

# -------------------------------
# 3. Join Excel with tables
# -------------------------------
result1 = spark_excel.join(llm_data, spark_excel.AudioID == llm_data.AUDIO_ID, "inner").drop(llm_data.AUDIO_ID)
stg_result = result1.join(pre_data, result1.AudioID == pre_data.AUDIO_ID, "inner").drop(pre_data.AUDIO_ID)

# -------------------------------
# 4. Flexible Filter for AudioIDs
# -------------------------------
# If you want specific AudioIDs, list them here
filter_audio_ids = [
    # "81D3EDEF-45E4-45BF-888A-D1536366986D",
    # "CCDEBCAF-70C2-41EF-8698-E4E29603359A"
]

if filter_audio_ids:  # Only apply filter if list is not empty
    final_result = stg_result.filter(F.col("AudioID").isin(filter_audio_ids))
else:
    final_result = stg_result  # No filter, include all AudioIDs

# -------------------------------
# 5. Extract last word if QuestionText has '?'
# -------------------------------
final_result = final_result.withColumn(
    "LastWord",
    F.when(
        F.col("QuestionText").rlike(r"\?"),
        F.regexp_extract(F.regexp_replace(F.col("QuestionText"), r"\?", ""), r"(\w+)$", 1)
    )
)

# -------------------------------
# 6. Concat QuestionID + LastWord
# -------------------------------
final_result = final_result.withColumn(
    "ConcatCol",
    F.when(F.col("LastWord").isNotNull(), F.concat_ws("_", F.col("QuestionID"), F.col("LastWord")))
)

# -------------------------------
# 7. Pivot/Transpose → one row per AudioID
# -------------------------------
pivot_df = final_result.groupBy("AudioID").pivot("ConcatCol").agg(F.first("ResponseText"))

# -------------------------------
# 8. Bring back metadata (Brand, Market, etc.)
# -------------------------------
meta_cols = ["AudioID", "BRAND", "MARKET", "TRANSCRIPT_ID"]
meta_df = final_result.select(meta_cols).dropDuplicates()

final_pivoted = meta_df.join(pivot_df, on="AudioID", how="inner")

# -------------------------------
# 9. Final Output
# -------------------------------
display(final_pivoted)





















import pandas as pd
from pyspark.sql.types import StructType, StructField, StringType
from pyspark.sql import functions as F

# -------------------------------
# 1. Read Excel into Spark
# -------------------------------
file_path = "/Workspace/Users/chandrabhanu.x.chandrabhanu@gsk.com/Feedback_Report.xlsx"
df_excel = pd.read_excel(file_path, sheet_name="Feedback Data", nrows=5000)

excel_columns = ["AudioID", "QuestionID", "QuestionText", "ResponseText"]
df_excel = df_excel[excel_columns]

schema = StructType([
    StructField("AudioID", StringType(), True),
    StructField("QuestionID", StringType(), True),
    StructField("QuestionText", StringType(), True),
    StructField("ResponseText", StringType(), True)
])

spark_excel = spark.createDataFrame(df_excel.astype(str), schema=schema)

# -------------------------------
# 2. Read Databricks tables
# -------------------------------
llm_output = spark.table("fieldforce_navigator_uat.llm_audio_insights_output")
pre_processed = spark.table("fieldforce_navigator_uat.audio_pre_processed_output")

llm_columns = ["AUDIO_ID", "LOCAL_LANGUAGE_AGREED_ACTIONS", "LOCAL_LANGUAGE_SUMMARY",
               "OVERALL_AREA_OF_INTEREST_INSIGHT", "OVERALL_OBJECTIONS"]
pre_processed_columns = ["AUDIO_ID", "BRAND", "MARKET", "TRANSCRIPT_ID"]

llm_data = llm_output.select(llm_columns)
pre_data = pre_processed.select(pre_processed_columns)

# -------------------------------
# 3. Join Excel with tables
# -------------------------------
result1 = spark_excel.join(llm_data, spark_excel.AudioID == llm_data.AUDIO_ID, "inner").drop(llm_data.AUDIO_ID)
stg_result = result1.join(pre_data, result1.AudioID == pre_data.AUDIO_ID, "inner").drop(pre_data.AUDIO_ID)

# -------------------------------
# 4. Filter for multiple AudioIDs (like SQL IN)
# -------------------------------
filter_audio_ids = [
    "81D3EDEF-45E4-45BF-888A-D1536366986D",
    "CCDEBCAF-70C2-41EF-8698-E4E29603359A"
]
final_result = stg_result.filter(F.col("AudioID").isin(filter_audio_ids))

# -------------------------------
# 5. Extract last word if QuestionText has '?'
# -------------------------------
final_result = final_result.withColumn(
    "LastWord",
    F.when(
        F.col("QuestionText").rlike(r"\?"),
        F.regexp_extract(F.regexp_replace(F.col("QuestionText"), r"\?", ""), r"(\w+)$", 1)
    )
)

# -------------------------------
# 6. Concat QuestionID + LastWord
# -------------------------------
final_result = final_result.withColumn(
    "ConcatCol",
    F.when(F.col("LastWord").isNotNull(), F.concat_ws("_", F.col("QuestionID"), F.col("LastWord")))
)

# -------------------------------
# 7. Pivot/Transpose → one row per AudioID
# -------------------------------
pivot_df = final_result.groupBy("AudioID").pivot("ConcatCol").agg(F.first("ResponseText"))

# -------------------------------
# 8. Bring back metadata (Brand, Market, etc.)
# -------------------------------
meta_cols = ["AudioID", "BRAND", "MARKET", "TRANSCRIPT_ID"]
meta_df = final_result.select(meta_cols).dropDuplicates()

final_pivoted = meta_df.join(pivot_df, on="AudioID", how="inner")

# -------------------------------
# 9. Final Output
# -------------------------------
display(final_pivoted)












from pyspark.sql import functions as F

# -------------------------------
# 1. Filter multiple AudioIDs
# -------------------------------
filter_audio_ids = [
    "81D3EDEF-45E4-45BF-888A-D1536366986D",
    "CCDEBCAF-70C2-41EF-8698-E4E29603359A"
]

final_result = stg_result.filter(F.col("AudioID").isin(filter_audio_ids))

# -------------------------------
# 2. Extract last word if QuestionText has "?"
# -------------------------------
# Remove "?" and get last word
final_result = final_result.withColumn(
    "LastWord",
    F.when(
        F.col("QuestionText").rlike(r"\?"),
        F.regexp_extract(F.regexp_replace(F.col("QuestionText"), r"\?", ""), r"(\w+)$", 1)
    )
)

# -------------------------------
# 3. Concat QuestionID and LastWord
# -------------------------------
final_result = final_result.withColumn(
    "ConcatCol",
    F.when(F.col("LastWord").isNotNull(), F.concat_ws("_", F.col("QuestionID"), F.col("LastWord")))
)

# -------------------------------
# 4. Pivot/Transpose the data
# -------------------------------
# Keep only required cols for pivot
pivot_df = final_result.groupBy("AudioID").pivot("ConcatCol").agg(F.first("ResponseText"))

# -------------------------------
# 5. Merge with other non-changing cols (Brand, Market, etc.)
# -------------------------------
# Drop duplicates (since they repeat per AudioID) and join back
meta_cols = ["AudioID", "BRAND", "MARKET", "TRANSCRIPT_ID"]
meta_df = final_result.select(meta_cols).dropDuplicates()

final_pivoted = meta_df.join(pivot_df, on="AudioID", how="inner")

# Show final output
display(final_pivoted)





import pandas as pd
from pyspark.sql.types import StructType, StructField, StringType


file_path = "/Workspace/Users/chandrabhanu.x.chandrabhanu@gsk.com/Feedback_Report.xlsx"
df_excel = pd.read_excel(file_path, sheet_name="Feedback Data", nrows=5000)


excel_columns = ["AudioID", "QuestionID", "QuestionText", "ResponseText"]
df_excel = df_excel[excel_columns]


schema = StructType([
    StructField("AudioID", StringType(), True),
    StructField("QuestionID", StringType(), True),
    StructField("QuestionText", StringType(), True),
    StructField("ResponseText", StringType(), True)
])


spark_excel = spark.createDataFrame(df_excel.astype(str), schema=schema)


llm_output = spark.table("fieldforce_navigator_uat.llm_audio_insights_output")
pre_processed = spark.table("fieldforce_navigator_uat.audio_pre_processed_output")


llm_columns = ["AUDIO_ID", "LOCAL_LANGUAGE_AGREED_ACTIONS", "LOCAL_LANGUAGE_SUMMARY",
               "OVERALL_AREA_OF_INTEREST_INSIGHT", "OVERALL_OBJECTIONS"]
pre_processed_columns = ["AUDIO_ID", "BRAND", "MARKET", "TRANSCRIPT_ID"]

llm_data = llm_output.select(llm_columns)
pre_data = pre_processed.select(pre_processed_columns)


result1 = spark_excel.join(llm_data, spark_excel.AudioID == llm_data.AUDIO_ID, "inner").drop(llm_data.AUDIO_ID)
stg_result = result1.join(pre_data, result1.AudioID == pre_data.AUDIO_ID, "inner").drop(pre_data.AUDIO_ID)

filter_audio_id = "81D3EDEF-45E4-45BF-888A-D1536366986D"
#"CCDEBCAF-70C2-41EF-8698-E4E29603359A"
final_result = stg_result.filter(stg_result.AudioID == filter_audio_id)


display(final_result)




















%pip install openpyxl
import pandas as pd
from pyspark.sql.types import StructType, StructField, StringType

# 1. Read Excel with pandas
file_path = "/dbfs/Workspace/Users/chandrabhanu.x.chandrabhanu@gsk.com/Feedback_Report.xlsx"
df_excel = pd.read_excel(file_path, sheet_name="Feedback Data", nrows=5000)

# 2. Keep only required columns
excel_columns = ["AudioID", "QuestionID", "QuestionText"]
df_excel = df_excel[excel_columns]

# 3. Define schema so AudioID is forced as string
schema = StructType([
    StructField("AudioID", StringType(), True),
    StructField("QuestionID", StringType(), True),
    StructField("QuestionText", StringType(), True)
])

# 4. Create Spark DataFrame from Excel
spark_excel = spark.createDataFrame(df_excel.astype(str), schema=schema)

# 5. Read Spark tables
llm_output = spark.table("fieldforce_navigator_uat.llm_audio_insights_output")
pre_processed = spark.table("fieldforce_navigator_uat.audio_pre_processed_output")

# 6. Select required columns
llm_columns = ["AUDIO_ID", "LOCAL_LANGUAGE_AGREED_ACTIONS", "LOCAL_LANGUAGE_SUMMARY",
               "OVERALL_AREA_OF_INTEREST_INSIGHT", "OVERALL_OBJECTIONS"]
pre_processed_columns = ["AUDIO_ID", "BRAND", "MARKET", "TRANSCRIPT_ID"]

llm_data = llm_output.select(llm_columns)
pre_data = pre_processed.select(pre_processed_columns)

# 7. Join Excel(AudioID) with tables(AUDIO_ID)
result1 = spark_excel.join(llm_data, spark_excel.AudioID == llm_data.AUDIO_ID, "inner")
final_result = result1.join(pre_data, result1.AudioID == pre_data.AUDIO_ID, "inner")

# 8. Show final result
display(final_result)






%pip install openpyxl
import pandas as pd

# 1. Read Excel into Pandas
file_path = "/dbfs/Workspace/Users/chandrabhanu.x.chandrabhanu@gsk.com/Feedback_Report.xlsx"
df_excel = pd.read_excel(file_path, sheet_name="Feedback Data", nrows=5000)

# 2. Select required columns
excel_columns = ["AudioID", "QuestionID", "QuestionText"]
df_excel = df_excel[excel_columns]

# 3. Ensure AudioID is string (avoid Arrow error)
df_excel["AudioID"] = df_excel["AudioID"].astype(str)

# 4. Convert Pandas → Spark
spark_excel = spark.createDataFrame(df_excel)

# 5. Rename Excel column to match table column
spark_excel = spark_excel.withColumnRenamed("AudioID", "AUDIO_ID")

# 6. Read Spark tables
llm_output = spark.table("fieldforce_navigator_uat.llm_audio_insights_output")
pre_processed = spark.table("fieldforce_navigator_uat.audio_pre_processed_output")

# 7. Select required columns
llm_columns = ["AUDIO_ID", "LOCAL_LANGUAGE_AGREED_ACTIONS", "LOCAL_LANGUAGE_SUMMARY", 
               "OVERALL_AREA_OF_INTEREST_INSIGHT", "OVERALL_OBJECTIONS"]
pre_processed_columns = ["AUDIO_ID", "BRAND", "MARKET", "TRANSCRIPT_ID"]

llm_data = llm_output.select(llm_columns)
pre_data = pre_processed.select(pre_processed_columns)

# 8. Join on AUDIO_ID
result1 = spark_excel.join(llm_data, "AUDIO_ID", "inner")
final_result = result1.join(pre_data, "AUDIO_ID", "inner")

# 9. Show result
display(final_result)

