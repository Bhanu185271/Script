from pyspark.sql import functions as F

# -------------------------------
# 1. Filter multiple AudioIDs
# -------------------------------
filter_audio_ids = [
    "81D3EDEF-45E4-45BF-888A-D1536366986D",
    "CCDEBCAF-70C2-41EF-8698-E4E29603359A"
]

final_result = stg_result.filter(F.col("AudioID").isin(filter_audio_ids))

# -------------------------------
# 2. Extract last word if QuestionText has "?"
# -------------------------------
# Remove "?" and get last word
final_result = final_result.withColumn(
    "LastWord",
    F.when(
        F.col("QuestionText").rlike(r"\?"),
        F.regexp_extract(F.regexp_replace(F.col("QuestionText"), r"\?", ""), r"(\w+)$", 1)
    )
)

# -------------------------------
# 3. Concat QuestionID and LastWord
# -------------------------------
final_result = final_result.withColumn(
    "ConcatCol",
    F.when(F.col("LastWord").isNotNull(), F.concat_ws("_", F.col("QuestionID"), F.col("LastWord")))
)

# -------------------------------
# 4. Pivot/Transpose the data
# -------------------------------
# Keep only required cols for pivot
pivot_df = final_result.groupBy("AudioID").pivot("ConcatCol").agg(F.first("ResponseText"))

# -------------------------------
# 5. Merge with other non-changing cols (Brand, Market, etc.)
# -------------------------------
# Drop duplicates (since they repeat per AudioID) and join back
meta_cols = ["AudioID", "BRAND", "MARKET", "TRANSCRIPT_ID"]
meta_df = final_result.select(meta_cols).dropDuplicates()

final_pivoted = meta_df.join(pivot_df, on="AudioID", how="inner")

# Show final output
display(final_pivoted)





import pandas as pd
from pyspark.sql.types import StructType, StructField, StringType


file_path = "/Workspace/Users/chandrabhanu.x.chandrabhanu@gsk.com/Feedback_Report.xlsx"
df_excel = pd.read_excel(file_path, sheet_name="Feedback Data", nrows=5000)


excel_columns = ["AudioID", "QuestionID", "QuestionText", "ResponseText"]
df_excel = df_excel[excel_columns]


schema = StructType([
    StructField("AudioID", StringType(), True),
    StructField("QuestionID", StringType(), True),
    StructField("QuestionText", StringType(), True),
    StructField("ResponseText", StringType(), True)
])


spark_excel = spark.createDataFrame(df_excel.astype(str), schema=schema)


llm_output = spark.table("fieldforce_navigator_uat.llm_audio_insights_output")
pre_processed = spark.table("fieldforce_navigator_uat.audio_pre_processed_output")


llm_columns = ["AUDIO_ID", "LOCAL_LANGUAGE_AGREED_ACTIONS", "LOCAL_LANGUAGE_SUMMARY",
               "OVERALL_AREA_OF_INTEREST_INSIGHT", "OVERALL_OBJECTIONS"]
pre_processed_columns = ["AUDIO_ID", "BRAND", "MARKET", "TRANSCRIPT_ID"]

llm_data = llm_output.select(llm_columns)
pre_data = pre_processed.select(pre_processed_columns)


result1 = spark_excel.join(llm_data, spark_excel.AudioID == llm_data.AUDIO_ID, "inner").drop(llm_data.AUDIO_ID)
stg_result = result1.join(pre_data, result1.AudioID == pre_data.AUDIO_ID, "inner").drop(pre_data.AUDIO_ID)

filter_audio_id = "81D3EDEF-45E4-45BF-888A-D1536366986D"
#"CCDEBCAF-70C2-41EF-8698-E4E29603359A"
final_result = stg_result.filter(stg_result.AudioID == filter_audio_id)


display(final_result)




















%pip install openpyxl
import pandas as pd
from pyspark.sql.types import StructType, StructField, StringType

# 1. Read Excel with pandas
file_path = "/dbfs/Workspace/Users/chandrabhanu.x.chandrabhanu@gsk.com/Feedback_Report.xlsx"
df_excel = pd.read_excel(file_path, sheet_name="Feedback Data", nrows=5000)

# 2. Keep only required columns
excel_columns = ["AudioID", "QuestionID", "QuestionText"]
df_excel = df_excel[excel_columns]

# 3. Define schema so AudioID is forced as string
schema = StructType([
    StructField("AudioID", StringType(), True),
    StructField("QuestionID", StringType(), True),
    StructField("QuestionText", StringType(), True)
])

# 4. Create Spark DataFrame from Excel
spark_excel = spark.createDataFrame(df_excel.astype(str), schema=schema)

# 5. Read Spark tables
llm_output = spark.table("fieldforce_navigator_uat.llm_audio_insights_output")
pre_processed = spark.table("fieldforce_navigator_uat.audio_pre_processed_output")

# 6. Select required columns
llm_columns = ["AUDIO_ID", "LOCAL_LANGUAGE_AGREED_ACTIONS", "LOCAL_LANGUAGE_SUMMARY",
               "OVERALL_AREA_OF_INTEREST_INSIGHT", "OVERALL_OBJECTIONS"]
pre_processed_columns = ["AUDIO_ID", "BRAND", "MARKET", "TRANSCRIPT_ID"]

llm_data = llm_output.select(llm_columns)
pre_data = pre_processed.select(pre_processed_columns)

# 7. Join Excel(AudioID) with tables(AUDIO_ID)
result1 = spark_excel.join(llm_data, spark_excel.AudioID == llm_data.AUDIO_ID, "inner")
final_result = result1.join(pre_data, result1.AudioID == pre_data.AUDIO_ID, "inner")

# 8. Show final result
display(final_result)






%pip install openpyxl
import pandas as pd

# 1. Read Excel into Pandas
file_path = "/dbfs/Workspace/Users/chandrabhanu.x.chandrabhanu@gsk.com/Feedback_Report.xlsx"
df_excel = pd.read_excel(file_path, sheet_name="Feedback Data", nrows=5000)

# 2. Select required columns
excel_columns = ["AudioID", "QuestionID", "QuestionText"]
df_excel = df_excel[excel_columns]

# 3. Ensure AudioID is string (avoid Arrow error)
df_excel["AudioID"] = df_excel["AudioID"].astype(str)

# 4. Convert Pandas â†’ Spark
spark_excel = spark.createDataFrame(df_excel)

# 5. Rename Excel column to match table column
spark_excel = spark_excel.withColumnRenamed("AudioID", "AUDIO_ID")

# 6. Read Spark tables
llm_output = spark.table("fieldforce_navigator_uat.llm_audio_insights_output")
pre_processed = spark.table("fieldforce_navigator_uat.audio_pre_processed_output")

# 7. Select required columns
llm_columns = ["AUDIO_ID", "LOCAL_LANGUAGE_AGREED_ACTIONS", "LOCAL_LANGUAGE_SUMMARY", 
               "OVERALL_AREA_OF_INTEREST_INSIGHT", "OVERALL_OBJECTIONS"]
pre_processed_columns = ["AUDIO_ID", "BRAND", "MARKET", "TRANSCRIPT_ID"]

llm_data = llm_output.select(llm_columns)
pre_data = pre_processed.select(pre_processed_columns)

# 8. Join on AUDIO_ID
result1 = spark_excel.join(llm_data, "AUDIO_ID", "inner")
final_result = result1.join(pre_data, "AUDIO_ID", "inner")

# 9. Show result
display(final_result)

