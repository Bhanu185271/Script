# d_ffn_insight_config - Multiple Independent Endpoints
# Fixed version with unique function names for each endpoint

INSIGHT_TABLE = "hive_metastore.fieldforce_navigator_deployment.d_ffn_insight_config"
MARKET_BRAND_TABLE = "hive_metastore.fieldforce_navigator_deployment.audio_market_brand_config"

# Shared cache for all endpoints
_valid_markets_brands_cache = None
_cache_timestamp = None

import time
from datetime import datetime, timedelta
import pandas as pd

# ============================================================================
# SHARED UTILITY FUNCTIONS (used by all endpoints)
# ============================================================================

def _clean(s):  
    return " ".join(str(s).strip().split()) if s is not None else ""

def _sq(s):     
    return str(s).replace("'", "''")

def _is_nullish(v):
    if v is None:
        return True
    t = str(v).strip()
    if t == "":
        return True
    return t.lower() == "null"

def _get_valid_markets_brands(force_refresh=False):
    """Get valid markets and brands from audio_market_brand_config, cached for 5 min"""
    global _valid_markets_brands_cache, _cache_timestamp
    
    cache_duration = timedelta(minutes=5)
    current_time = datetime.now()
    
    if (not force_refresh and 
        _valid_markets_brands_cache is not None and 
        _cache_timestamp is not None and 
        current_time - _cache_timestamp < cache_duration):
        return _valid_markets_brands_cache
    
    try:
        sql = f"""
            SELECT 
                DISTINCT UPPER(TRIM(MARKET)) as MARKET,
                UPPER(TRIM(BRAND)) as BRAND
            FROM {MARKET_BRAND_TABLE}
            WHERE MARKET IS NOT NULL AND BRAND IS NOT NULL
        """
        
        df = dc.execute_query(sql)
        
        if df is not None and not df.empty:
            valid_markets = set(df['MARKET'].dropna().unique())
            valid_brands = set(df['BRAND'].dropna().unique())
            
            valid_combinations = set()
            for _, row in df.iterrows():
                if pd.notna(row['MARKET']) and pd.notna(row['BRAND']):
                    valid_combinations.add((row['MARKET'], row['BRAND']))
            
            _valid_markets_brands_cache = {
                'markets': valid_markets,
                'brands': valid_brands,
                'combinations': valid_combinations
            }
            _cache_timestamp = current_time
        else:
            _valid_markets_brands_cache = {
                'markets': set(),
                'brands': set(),
                'combinations': set()
            }
            _cache_timestamp = current_time
            
    except Exception as e:
        print(f"Error fetching valid markets/brands: {str(e)}")
        return {'markets': set(), 'brands': set(), 'combinations': set()}
    
    return _valid_markets_brands_cache

def _validate_market_brand_separately(market, brand):
    """Check if market AND brand exist separately in audio_market_brand_config"""
    valid_data = _get_valid_markets_brands()
    
    market_upper = market.upper().strip()
    brand_upper = brand.upper().strip()
    
    market_valid = market_upper in valid_data['markets']
    brand_valid = brand_upper in valid_data['brands']
    
    return market_valid, brand_valid


# ============================================================================
# ENDPOINT 1: KEY MESSAGES
# ============================================================================

EXCEL_TO_DB_MAPPING_KEY_MSG = {
    "Market": "MARKET",
    "Brand": "BRAND",
    "Message": "VALUE_1"
}

FIXED_INSIGHT_VALUE_KEY_MSG = "mkt-key-messages-categorization-insight"
FIXED_TYPE_VALUE_KEY_MSG = "Market_Intelligence"
TARGET_SHEET_NAME_KEY_MSG = "Brand - Key Messages"
HEADER_ROW_INDEX_KEY_MSG = 2

def _batch_check_duplicates_key_msg(rows):
    """Batch duplicate check for Key Messages endpoint"""
    if not rows:
        return set()
    
    duplicate_set = set()
    chunk_size = 25
    
    for chunk_start in range(0, len(rows), chunk_size):
        chunk_rows = rows[chunk_start:chunk_start + chunk_size]
        conditions = []
        
        for r in chunk_rows:
            market = _sq(r["MARKET"].upper())
            brand = _sq(r["BRAND"].upper())
            insight = _sq(r["INSIGHT"])
            type_val = _sq(r["TYPE"])
            value_1 = _sq(r["VALUE_1"])
            
            conditions.append(
                f"(UPPER(TRIM(MARKET)) = '{market}' AND "
                f"UPPER(TRIM(BRAND)) = '{brand}' AND "
                f"TRIM(INSIGHT) = '{insight}' AND "
                f"TRIM(TYPE) = '{type_val}' AND "
                f"TRIM(VALUE_1) = '{value_1}')"
            )
        
        sql = f"""
            SELECT UPPER(TRIM(MARKET)) as MARKET,
                   UPPER(TRIM(BRAND)) as BRAND,
                   TRIM(INSIGHT) as INSIGHT,
                   TRIM(TYPE) as TYPE,
                   TRIM(VALUE_1) as VALUE_1
            FROM {INSIGHT_TABLE}
            WHERE {' OR '.join(conditions)}
        """
        
        try:
            df = dc.execute_query(sql)
            if df is not None and not df.empty:
                for _, row in df.iterrows():
                    duplicate_set.add((
                        row['MARKET'], 
                        row['BRAND'], 
                        row['INSIGHT'],
                        row['TYPE'],
                        row['VALUE_1']
                    ))
        except Exception as e:
            print(f"Batch duplicate check error (chunk {chunk_start//chunk_size + 1}): {str(e)}")
    
    return duplicate_set

def _batch_insert_rows_key_msg(rows, added_by):
    """Batch insert for Key Messages endpoint"""
    if not rows:
        return 0
    
    total_inserted = 0
    chunk_size = 25
    
    for chunk_start in range(0, len(rows), chunk_size):
        chunk_rows = rows[chunk_start:chunk_start + chunk_size]
        
        for r in chunk_rows:
            market_upper = r['MARKET'].upper()
            brand_upper = r['BRAND'].upper()
            
            sql = f"""
                INSERT INTO {INSIGHT_TABLE}
                    (BRAND, MARKET, INSIGHT, TYPE, VALUE_1, VALUE_2, VALUE_3, VALUE_4, ADDED_BY, ENTRY_TIME)
                VALUES
                    ('{_sq(brand_upper)}', '{_sq(market_upper)}', '{_sq(r['INSIGHT'])}', '{_sq(r['TYPE'])}',
                     '{_sq(r['VALUE_1'])}', NULL, NULL, NULL,
                     '{_sq(added_by)}', CURRENT_TIMESTAMP())
            """
            
            try:
                dc.execute_non_query(sql)
                total_inserted += 1
            except Exception as e:
                print(f"Insert error: {str(e)}")
                raise
    
    return total_inserted

def _process_template_excel_key_msg(file_obj):
    """Process Excel template for Key Messages endpoint"""
    try:
        excel_file = pd.ExcelFile(file_obj, engine="openpyxl")
        
        if TARGET_SHEET_NAME_KEY_MSG not in excel_file.sheet_names:
            raise ValueError(
                f"Required sheet '{TARGET_SHEET_NAME_KEY_MSG}' not found. "
                f"Available sheets: {', '.join(excel_file.sheet_names)}"
            )
        
        df = pd.read_excel(
            file_obj, 
            sheet_name=TARGET_SHEET_NAME_KEY_MSG,
            header=HEADER_ROW_INDEX_KEY_MSG,
            engine="openpyxl"
        )
        
        if len(df.columns) > 0:
            df = df.iloc[:, 1:]  # skip first column
        
        df.columns = [str(c).strip() for c in df.columns]
        df = df.replace({pd.NA: "", None: ""}).fillna("")
        
        df['_excel_row_num'] = range(4, 4 + len(df))
        df = df[df.drop('_excel_row_num', axis=1).astype(str).apply(lambda x: x.str.strip().str.len().sum(), axis=1) > 0]
        
        available_excel_cols = set(df.columns) - {'_excel_row_num'}
        expected_excel_cols = set(EXCEL_TO_DB_MAPPING_KEY_MSG.keys())
        missing_cols = expected_excel_cols - available_excel_cols
        
        missing_columns_list = list(missing_cols) if missing_cols else None
        
        mandatory_excel_cols = ["Market", "Brand", "Message"]
        missing_mandatory = [col for col in mandatory_excel_cols if col not in df.columns]
        
        if missing_mandatory:
            raise ValueError(
                f"Missing mandatory columns in '{TARGET_SHEET_NAME_KEY_MSG}' sheet: {', '.join(missing_mandatory)}. "
                f"Found columns: {list(df.columns)}"
            )
        
        mapped_data = []
        
        for idx, row in df.iterrows():
            excel_row_num = int(row['_excel_row_num'])
            mapped_row = {}
            
            for excel_col, db_col in EXCEL_TO_DB_MAPPING_KEY_MSG.items():
                if excel_col in df.columns:
                    value = row.get(excel_col, "")
                    mapped_row[db_col] = _clean(value)
                else:
                    mapped_row[db_col] = ""
            
            mapped_row["INSIGHT"] = FIXED_INSIGHT_VALUE_KEY_MSG
            mapped_row["TYPE"] = FIXED_TYPE_VALUE_KEY_MSG
            mapped_row["VALUE_2"] = None
            mapped_row["VALUE_3"] = None
            mapped_row["VALUE_4"] = None
            
            if (mapped_row.get("MARKET") and 
                mapped_row.get("BRAND") and 
                mapped_row.get("VALUE_1")):
                mapped_data.append((excel_row_num, mapped_row))
        
        if not mapped_data:
            raise ValueError(
                f"No valid data rows found in sheet '{TARGET_SHEET_NAME_KEY_MSG}'. "
                f"Ensure mandatory fields (Market, Brand, Message) have values."
            )
        
        return mapped_data, missing_columns_list
        
    except Exception as e:
        raise Exception(f"Error processing template Excel: {str(e)}")

@app.route("/d_ffn_insight_config_key_msg", methods=["GET"])
def insight_key_msg_get():
    try:
        definitions = {
            "Description": {
                "BRAND": {
                    "Example Values": ["AREXVY", "SHINGRIX"],
                    "Description": "Name of Brand to be deployed",
                    "Parameter_type": "Mandatory"
                },
                "MARKET": {
                    "Example Values": ["GBR", "THA", "ITA", "PRT"],
                    "Description": "Name of the Market to be deployed",
                    "Parameter_type": "Mandatory"
                },
                "INSIGHT": {
                    "Example Values": ["mkt-key-messages-categorization-insight"],
                    "Description": "Fixed value for insight type",
                    "Parameter_type": "Auto-filled (Fixed Value)"
                },
                "TYPE": {
                    "Example Values": ["Market_Intelligence"],
                    "Description": "Fixed value for type",
                    "Parameter_type": "Auto-filled (Fixed Value)"
                },
                "VALUE_1": {
                    "Example Values": ["Key message text"],
                    "Description": "The actual key message content",
                    "Parameter_type": "Mandatory"
                },
                "VALUE_2": {
                    "Example Values": ["NULL"],
                    "Description": "Reserved for future use",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "VALUE_3": {
                    "Example Values": ["NULL"],
                    "Description": "Reserved for future use",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "VALUE_4": {
                    "Example Values": ["NULL"],
                    "Description": "Reserved for future use",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "ADDED_BY": {
                    "Example Values": ["abc.x.abc@gsk.com"],
                    "Description": "Auto-picked from 'Username' header in POST",
                    "Parameter_type": "Mandatory (via header)"
                },
                "ENTRY_TIME": {
                    "Example Values": ["current_timestamp()"],
                    "Description": "Set by system at insert time",
                    "Parameter_type": "Auto-generated"
                }
            },
            "sample_json": {
                "MARKET": "THA",
                "BRAND": "AREXVY",
                "VALUE_1": "This is a key message"
            },
            "excel_upload_instructions": {
                "expected_extension": ".xlsx",
                "template_sheet_name": TARGET_SHEET_NAME_KEY_MSG,
                "header_row": HEADER_ROW_INDEX_KEY_MSG + 1,
                "form_field_name": "file",
                "required_columns": ["Market", "Brand", "Message"],
                "column_mapping": EXCEL_TO_DB_MAPPING_KEY_MSG,
                "fixed_values": {
                    "INSIGHT": FIXED_INSIGHT_VALUE_KEY_MSG,
                    "TYPE": FIXED_TYPE_VALUE_KEY_MSG,
                    "VALUE_2": "NULL",
                    "VALUE_3": "NULL",
                    "VALUE_4": "NULL"
                },
                "notes": [
                    "Tablename: hive_metastore.fieldforce_navigator_deployment.d_ffn_insight_config",
                    f"The Excel file must contain a sheet named '{TARGET_SHEET_NAME_KEY_MSG}'",
                    f"Headers must be in row {HEADER_ROW_INDEX_KEY_MSG + 1} of the sheet, starting from Column B",
                    "Data rows should start from row 4 onwards, Column B onwards",
                    "Column A is ignored during processing",
                    "INSIGHT and TYPE are automatically set to fixed values",
                    "VALUE_2, VALUE_3, VALUE_4 are automatically set to NULL"
                ]
            }
        }
        return jsonify(definitions), status.HTTP_200_OK
    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR

@app.route("/d_ffn_insight_config_key_msg", methods=["POST"])
def insight_key_msg_post():
    try:
        added_by = _clean(request.headers.get("Username", "") or "")
        if not added_by:
            return jsonify({"error": "Missing 'Username' in headers."}), status.HTTP_400_BAD_REQUEST

        _get_valid_markets_brands(force_refresh=True)

        rows = []
        is_excel_mode = False
        missing_columns_warning = None

        if "file" in request.files:
            is_excel_mode = True
            f = request.files["file"]
            fname = (f.filename or "").lower().strip()
            
            if not fname.endswith(".xlsx"):
                return jsonify({
                    "error": "Only .xlsx files are supported for bulk upload."
                }), status.HTTP_400_BAD_REQUEST

            try:
                rows, missing_columns_warning = _process_template_excel_key_msg(f)
                
                if not rows:
                    return jsonify({
                        "error": f"No valid data rows found in sheet '{TARGET_SHEET_NAME_KEY_MSG}'."
                    }), status.HTTP_400_BAD_REQUEST
                
            except ValueError as ve:
                return jsonify({"error": str(ve)}), status.HTTP_400_BAD_REQUEST
            except Exception as e:
                return jsonify({
                    "error": f"Failed to process Excel template: {str(e)}"
                }), status.HTTP_400_BAD_REQUEST

        else:
            body = request.get_json(force=True, silent=True) or {}
            items = body if isinstance(body, list) else [body]

            for i, rec in enumerate(items, start=1):
                market = _clean(rec.get("MARKET", ""))
                brand  = _clean(rec.get("BRAND", ""))
                value_1 = _clean(rec.get("VALUE_1", ""))

                if not market or not brand or not value_1:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Missing required field(s). MARKET, BRAND, and VALUE_1 are mandatory."
                    }), status.HTTP_400_BAD_REQUEST

                market_valid, brand_valid = _validate_market_brand_separately(market, brand)
                
                if not market_valid:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Invalid MARKET '{market}'. This market does not exist."
                    }), status.HTTP_400_BAD_REQUEST
                
                if not brand_valid:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Invalid BRAND '{brand}'. This brand does not exist."
                    }), status.HTTP_400_BAD_REQUEST

                rows.append((i, {
                    "MARKET": market,
                    "BRAND": brand,
                    "INSIGHT": FIXED_INSIGHT_VALUE_KEY_MSG,
                    "TYPE": FIXED_TYPE_VALUE_KEY_MSG,
                    "VALUE_1": value_1,
                    "VALUE_2": None,
                    "VALUE_3": None,
                    "VALUE_4": None
                }))

        if not rows:
            return jsonify({"error": "No valid rows to process."}), status.HTTP_400_BAD_REQUEST

        invalid_markets = []
        invalid_brands = []
        valid_rows = []
        
        valid_data = _get_valid_markets_brands()
        
        for row_num, r in rows:
            market = r["MARKET"]
            brand = r["BRAND"]
            
            market_valid = market.upper().strip() in valid_data['markets']
            brand_valid = brand.upper().strip() in valid_data['brands']
            
            if not market_valid:
                invalid_markets.append({
                    "excel_row": row_num,
                    "MARKET": market,
                    "BRAND": brand,
                    "reason": "Invalid MARKET - not found in audio_market_brand_config"
                })
                continue
            
            if not brand_valid:
                invalid_brands.append({
                    "excel_row": row_num,
                    "MARKET": market,
                    "BRAND": brand,
                    "reason": "Invalid BRAND - not found in audio_market_brand_config"
                })
                continue
            
            valid_rows.append((row_num, r))
        
        duplicate_set = _batch_check_duplicates_key_msg([r for _, r in valid_rows])
        
        duplicates = []
        insertable_rows = []
        
        for row_num, r in valid_rows:
            key = (
                r["MARKET"].upper().strip(),
                r["BRAND"].upper().strip(),
                r["INSIGHT"].strip(),
                r["TYPE"].strip(),
                r["VALUE_1"].strip()
            )
            
            if key in duplicate_set:
                duplicates.append({
                    "excel_row": row_num,
                    "MARKET": r["MARKET"],
                    "BRAND": r["BRAND"],
                    "VALUE_1": r["VALUE_1"],
                    "reason": "Duplicate - already exists in database"
                })
            else:
                insertable_rows.append(r)
        
        inserted = 0
        errors = []
        
        if insertable_rows:
            try:
                inserted = _batch_insert_rows_key_msg(insertable_rows, added_by)
            except Exception as e:
                errors.append({
                    "error": f"Batch insert failed: {str(e)}"
                })

        response = {
            "status": "success" if inserted and not errors else ("partial" if inserted else "no-change"),
            "mode": "excel-template" if is_excel_mode else "json",
            "sheet_processed": TARGET_SHEET_NAME_KEY_MSG if is_excel_mode else None,
            "total_rows_processed": len(rows),
            "inserted_count": inserted,
            "duplicate_count": len(duplicates),
            "validation_errors_count": len(invalid_markets) + len(invalid_brands),
            "skipped_duplicates": duplicates,
            "invalid_markets": invalid_markets,
            "invalid_brands": invalid_brands,
            "row_errors": errors
        }
        
        if is_excel_mode and missing_columns_warning:
            response["warning"] = {
                "message": "The uploaded Excel template is missing some required columns.",
                "missing_columns": missing_columns_warning,
                "note": "All three columns (Market, Brand, Message) are required for Insight Config."
            }
        
        response = {k: v for k, v in response.items() 
                   if v is not None and not (isinstance(v, list) and len(v) == 0)}
        
        if inserted > 0:
            status_code = status.HTTP_201_CREATED
        elif invalid_markets or invalid_brands:
            status_code = status.HTTP_207_MULTI_STATUS
        else:
            status_code = status.HTTP_200_OK
        
        return jsonify(response), status_code

    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR


# ============================================================================
# ENDPOINT 2: KEY OBJECTIONS
# ============================================================================

EXCEL_TO_DB_MAPPING_KEY_OBJ = {
    "Market": "MARKET",
    "Brand": "BRAND",
    "Objection": "VALUE_1"
}

FIXED_INSIGHT_VALUE_KEY_OBJ = "mkt-objections-categorization-insight"
FIXED_TYPE_VALUE_KEY_OBJ = "Market_Intelligence"
TARGET_SHEET_NAME_KEY_OBJ = "Brand - Objections & Handlers"
HEADER_ROW_INDEX_KEY_OBJ = 2

def _batch_check_duplicates_key_obj(rows):
    """Batch duplicate check for Key Objections endpoint"""
    if not rows:
        return set()
    
    duplicate_set = set()
    chunk_size = 25
    
    for chunk_start in range(0, len(rows), chunk_size):
        chunk_rows = rows[chunk_start:chunk_start + chunk_size]
        conditions = []
        
        for r in chunk_rows:
            market = _sq(r["MARKET"].upper())
            brand = _sq(r["BRAND"].upper())
            insight = _sq(r["INSIGHT"])
            type_val = _sq(r["TYPE"])
            value_1 = _sq(r["VALUE_1"])
            
            conditions.append(
                f"(UPPER(TRIM(MARKET)) = '{market}' AND "
                f"UPPER(TRIM(BRAND)) = '{brand}' AND "
                f"TRIM(INSIGHT) = '{insight}' AND "
                f"TRIM(TYPE) = '{type_val}' AND "
                f"TRIM(VALUE_1) = '{value_1}')"
            )
        
        sql = f"""
            SELECT UPPER(TRIM(MARKET)) as MARKET,
                   UPPER(TRIM(BRAND)) as BRAND,
                   TRIM(INSIGHT) as INSIGHT,
                   TRIM(TYPE) as TYPE,
                   TRIM(VALUE_1) as VALUE_1
            FROM {INSIGHT_TABLE}
            WHERE {' OR '.join(conditions)}
        """
        
        try:
            df = dc.execute_query(sql)
            if df is not None and not df.empty:
                for _, row in df.iterrows():
                    duplicate_set.add((
                        row['MARKET'], 
                        row['BRAND'], 
                        row['INSIGHT'],
                        row['TYPE'],
                        row['VALUE_1']
                    ))
        except Exception as e:
            print(f"Batch duplicate check error (chunk {chunk_start//chunk_size + 1}): {str(e)}")
    
    return duplicate_set

def _batch_insert_rows_key_obj(rows, added_by):
    """Batch insert for Key Objections endpoint"""
    if not rows:
        return 0
    
    total_inserted = 0
    chunk_size = 25
    
    for chunk_start in range(0, len(rows), chunk_size):
        chunk_rows = rows[chunk_start:chunk_start + chunk_size]
        
        for r in chunk_rows:
            market_upper = r['MARKET'].upper()
            brand_upper = r['BRAND'].upper()
            
            sql = f"""
                INSERT INTO {INSIGHT_TABLE}
                    (BRAND, MARKET, INSIGHT, TYPE, VALUE_1, VALUE_2, VALUE_3, VALUE_4, ADDED_BY, ENTRY_TIME)
                VALUES
                    ('{_sq(brand_upper)}', '{_sq(market_upper)}', '{_sq(r['INSIGHT'])}', '{_sq(r['TYPE'])}',
                     '{_sq(r['VALUE_1'])}', NULL, NULL, NULL,
                     '{_sq(added_by)}', CURRENT_TIMESTAMP())
            """
            
            try:
                dc.execute_non_query(sql)
                total_inserted += 1
            except Exception as e:
                print(f"Insert error: {str(e)}")
                raise
    
    return total_inserted

def _process_template_excel_key_obj(file_obj):
    """Process Excel template for Key Objections endpoint"""
    try:
        excel_file = pd.ExcelFile(file_obj, engine="openpyxl")
        
        if TARGET_SHEET_NAME_KEY_OBJ not in excel_file.sheet_names:
            raise ValueError(
                f"Required sheet '{TARGET_SHEET_NAME_KEY_OBJ}' not found. "
                f"Available sheets: {', '.join(excel_file.sheet_names)}"
            )
        
        df = pd.read_excel(
            file_obj, 
            sheet_name=TARGET_SHEET_NAME_KEY_OBJ,
            header=HEADER_ROW_INDEX_KEY_OBJ,
            engine="openpyxl"
        )
        
        if len(df.columns) > 0:
            df = df.iloc[:, 1:]
        
        df.columns = [str(c).strip() for c in df.columns]
        df = df.replace({pd.NA: "", None: ""}).fillna("")
        
        df['_excel_row_num'] = range(4, 4 + len(df))
        df = df[df.drop('_excel_row_num', axis=1).astype(str).apply(lambda x: x.str.strip().str.len().sum(), axis=1) > 0]
        
        available_excel_cols = set(df.columns) - {'_excel_row_num'}
        expected_excel_cols = set(EXCEL_TO_DB_MAPPING_KEY_OBJ.keys())
        missing_cols = expected_excel_cols - available_excel_cols
        
        missing_columns_list = list(missing_cols) if missing_cols else None
        
        mandatory_excel_cols = ["Market", "Brand", "Objection"]
        missing_mandatory = [col for col in mandatory_excel_cols if col not in df.columns]
        
        if missing_mandatory:
            raise ValueError(
                f"Missing mandatory columns in '{TARGET_SHEET_NAME_KEY_OBJ}' sheet: {', '.join(missing_mandatory)}. "
                f"Found columns: {list(df.columns)}"
            )
        
        mapped_data = []
        
        for idx, row in df.iterrows():
            excel_row_num = int(row['_excel_row_num'])
            mapped_row = {}
            
            for excel_col, db_col in EXCEL_TO_DB_MAPPING_KEY_OBJ.items():
                if excel_col in df.columns:
                    value = row.get(excel_col, "")
                    mapped_row[db_col] = _clean(value)
                else:
                    mapped_row[db_col] = ""
            
            mapped_row["INSIGHT"] = FIXED_INSIGHT_VALUE_KEY_OBJ
            mapped_row["TYPE"] = FIXED_TYPE_VALUE_KEY_OBJ
            mapped_row["VALUE_2"] = None
            mapped_row["VALUE_3"] = None
            mapped_row["VALUE_4"] = None
            
            if (mapped_row.get("MARKET") and 
                mapped_row.get("BRAND") and 
                mapped_row.get("VALUE_1")):
                mapped_data.append((excel_row_num, mapped_row))
        
        if not mapped_data:
            raise ValueError(
                f"No valid data rows found in sheet '{TARGET_SHEET_NAME_KEY_OBJ}'. "
                f"Ensure mandatory fields (Market, Brand, Objection) have values."
            )
        
        return mapped_data, missing_columns_list
        
    except Exception as e:
        raise Exception(f"Error processing template Excel: {str(e)}")

@app.route("/d_ffn_insight_config_key_obj", methods=["GET"])
def insight_key_obj_get():
    try:
        definitions = {
            "Description": {
                "BRAND": {
                    "Example Values": ["AREXVY", "SHINGRIX"],
                    "Description": "Name of Brand to be deployed",
                    "Parameter_type": "Mandatory"
                },
                "MARKET": {
                    "Example Values": ["GBR", "THA", "ITA", "PRT"],
                    "Description": "Name of the Market to be deployed",
                    "Parameter_type": "Mandatory"
                },
                "INSIGHT": {
                    "Example Values": ["mkt-objections-categorization-insight"],
                    "Description": "Fixed value for insight type",
                    "Parameter_type": "Auto-filled (Fixed Value)"
                },
                "TYPE": {
                    "Example Values": ["Market_Intelligence"],
                    "Description": "Fixed value for type",
                    "Parameter_type": "Auto-filled (Fixed Value)"
                },
                "VALUE_1": {
                    "Example Values": ["Key Objection text"],
                    "Description": "The actual key Objection content",
                    "Parameter_type": "Mandatory"
                },
                "VALUE_2": {
                    "Example Values": ["NULL"],
                    "Description": "Reserved for future use",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "VALUE_3": {
                    "Example Values": ["NULL"],
                    "Description": "Reserved for future use",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "VALUE_4": {
                    "Example Values": ["NULL"],
                    "Description": "Reserved for future use",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "ADDED_BY": {
                    "Example Values": ["abc.x.abc@gsk.com"],
                    "Description": "Auto-picked from 'Username' header in POST",
                    "Parameter_type": "Mandatory (via header)"
                },
                "ENTRY_TIME": {
                    "Example Values": ["current_timestamp()"],
                    "Description": "Set by system at insert time",
                    "Parameter_type": "Auto-generated"
                }
            },
            "sample_json": {
                "MARKET": "THA",
                "BRAND": "AREXVY",
                "VALUE_1": "This is a key Objection"
            },
            "excel_upload_instructions": {
                "expected_extension": ".xlsx",
                "template_sheet_name": TARGET_SHEET_NAME_KEY_OBJ,
                "header_row": HEADER_ROW_INDEX_KEY_OBJ + 1,
                "form_field_name": "file",
                "required_columns": ["Market", "Brand", "Objection"],
                "column_mapping": EXCEL_TO_DB_MAPPING_KEY_OBJ,
                "fixed_values": {
                    "INSIGHT": FIXED_INSIGHT_VALUE_KEY_OBJ,
                    "TYPE": FIXED_TYPE_VALUE_KEY_OBJ,
                    "VALUE_2": "NULL",
                    "VALUE_3": "NULL",
                    "VALUE_4": "NULL"
                },
                "notes": [
                    "Tablename: hive_metastore.fieldforce_navigator_deployment.d_ffn_insight_config",
                    f"The Excel file must contain a sheet named '{TARGET_SHEET_NAME_KEY_OBJ}'",
                    f"Headers must be in row {HEADER_ROW_INDEX_KEY_OBJ + 1} of the sheet, starting from Column B",
                    "Data rows should start from row 4 onwards, Column B onwards",
                    "Column A is ignored during processing",
                    "INSIGHT and TYPE are automatically set to fixed values",
                    "VALUE_2, VALUE_3, VALUE_4 are automatically set to NULL"
                ]
            }
        }
        return jsonify(definitions), status.HTTP_200_OK
    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR

@app.route("/d_ffn_insight_config_key_obj", methods=["POST"])
def insight_key_obj_post():
    try:
        added_by = _clean(request.headers.get("Username", "") or "")
        if not added_by:
            return jsonify({"error": "Missing 'Username' in headers."}), status.HTTP_400_BAD_REQUEST

        _get_valid_markets_brands(force_refresh=True)

        rows = []
        is_excel_mode = False
        missing_columns_warning = None

        if "file" in request.files:
            is_excel_mode = True
            f = request.files["file"]
            fname = (f.filename or "").lower().strip()
            
            if not fname.endswith(".xlsx"):
                return jsonify({
                    "error": "Only .xlsx files are supported for bulk upload."
                }), status.HTTP_400_BAD_REQUEST

            try:
                rows, missing_columns_warning = _process_template_excel_key_obj(f)
                
                if not rows:
                    return jsonify({
                        "error": f"No valid data rows found in sheet '{TARGET_SHEET_NAME_KEY_OBJ}'."
                    }), status.HTTP_400_BAD_REQUEST
                
            except ValueError as ve:
                return jsonify({"error": str(ve)}), status.HTTP_400_BAD_REQUEST
            except Exception as e:
                return jsonify({
                    "error": f"Failed to process Excel template: {str(e)}"
                }), status.HTTP_400_BAD_REQUEST

        else:
            body = request.get_json(force=True, silent=True) or {}
            items = body if isinstance(body, list) else [body]

            for i, rec in enumerate(items, start=1):
                market = _clean(rec.get("MARKET", ""))
                brand  = _clean(rec.get("BRAND", ""))
                value_1 = _clean(rec.get("VALUE_1", ""))

                if not market or not brand or not value_1:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Missing required field(s). MARKET, BRAND, and VALUE_1 are mandatory."
                    }), status.HTTP_400_BAD_REQUEST

                market_valid, brand_valid = _validate_market_brand_separately(market, brand)
                
                if not market_valid:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Invalid MARKET '{market}'. This market does not exist."
                    }), status.HTTP_400_BAD_REQUEST
                
                if not brand_valid:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Invalid BRAND '{brand}'. This brand does not exist."
                    }), status.HTTP_400_BAD_REQUEST

                rows.append((i, {
                    "MARKET": market,
                    "BRAND": brand,
                    "INSIGHT": FIXED_INSIGHT_VALUE_KEY_OBJ,
                    "TYPE": FIXED_TYPE_VALUE_KEY_OBJ,
                    "VALUE_1": value_1,
                    "VALUE_2": None,
                    "VALUE_3": None,
                    "VALUE_4": None
                }))

        if not rows:
            return jsonify({"error": "No valid rows to process."}), status.HTTP_400_BAD_REQUEST

        invalid_markets = []
        invalid_brands = []
        valid_rows = []
        
        valid_data = _get_valid_markets_brands()
        
        for row_num, r in rows:
            market = r["MARKET"]
            brand = r["BRAND"]
            
            market_valid = market.upper().strip() in valid_data['markets']
            brand_valid = brand.upper().strip() in valid_data['brands']
            
            if not market_valid:
                invalid_markets.append({
                    "excel_row": row_num,
                    "MARKET": market,
                    "BRAND": brand,
                    "reason": "Invalid MARKET - not found in audio_market_brand_config"
                })
                continue
            
            if not brand_valid:
                invalid_brands.append({
                    "excel_row": row_num,
                    "MARKET": market,
                    "BRAND": brand,
                    "reason": "Invalid BRAND - not found in audio_market_brand_config"
                })
                continue
            
            valid_rows.append((row_num, r))
        
        duplicate_set = _batch_check_duplicates_key_obj([r for _, r in valid_rows])
        
        duplicates = []
        insertable_rows = []
        
        for row_num, r in valid_rows:
            key = (
                r["MARKET"].upper().strip(),
                r["BRAND"].upper().strip(),
                r["INSIGHT"].strip(),
                r["TYPE"].strip(),
                r["VALUE_1"].strip()
            )
            
            if key in duplicate_set:
                duplicates.append({
                    "excel_row": row_num,
                    "MARKET": r["MARKET"],
                    "BRAND": r["BRAND"],
                    "VALUE_1": r["VALUE_1"],
                    "reason": "Duplicate - already exists in database"
                })
            else:
                insertable_rows.append(r)
        
        inserted = 0
        errors = []
        
        if insertable_rows:
            try:
                inserted = _batch_insert_rows_key_obj(insertable_rows, added_by)
            except Exception as e:
                errors.append({
                    "error": f"Batch insert failed: {str(e)}"
                })

        response = {
            "status": "success" if inserted and not errors else ("partial" if inserted else "no-change"),
            "mode": "excel-template" if is_excel_mode else "json",
            "sheet_processed": TARGET_SHEET_NAME_KEY_OBJ if is_excel_mode else None,
            "total_rows_processed": len(rows),
            "inserted_count": inserted,
            "duplicate_count": len(duplicates),
            "validation_errors_count": len(invalid_markets) + len(invalid_brands),
            "skipped_duplicates": duplicates,
            "invalid_markets": invalid_markets,
            "invalid_brands": invalid_brands,
            "row_errors": errors
        }
        
        if is_excel_mode and missing_columns_warning:
            response["warning"] = {
                "message": "The uploaded Excel template is missing some required columns.",
                "missing_columns": missing_columns_warning,
                "note": "All three columns (Market, Brand, Objection) are required for Insight Config."
            }
        
        response = {k: v for k, v in response.items() 
                   if v is not None and not (isinstance(v, list) and len(v) == 0)}
        
        if inserted > 0:
            status_code = status.HTTP_201_CREATED
        elif invalid_markets or invalid_brands:
            status_code = status.HTTP_207_MULTI_STATUS
        else:
            status_code = status.HTTP_200_OK
        
        return jsonify(response), status_code

    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR


# ============================================================================
# ENDPOINT 3: BRAND STUDIES
# ============================================================================

EXCEL_TO_DB_MAPPING_BRAND_STUDY = {
    "Market": "MARKET",
    "Brand": "BRAND",
    "Study Name": "VALUE_1"
}

FIXED_INSIGHT_VALUE_BRAND_STUDY = "medical-word-reassignment"
FIXED_TYPE_VALUE_BRAND_STUDY = "STUDY"
TARGET_SHEET_NAME_BRAND_STUDY = "Brand - Studies"
HEADER_ROW_INDEX_BRAND_STUDY = 2

def _batch_check_duplicates_brand_study(rows):
    """Batch duplicate check for Brand Studies endpoint"""
    if not rows:
        return set()
    
    duplicate_set = set()
    chunk_size = 25
    
    for chunk_start in range(0, len(rows), chunk_size):
        chunk_rows = rows[chunk_start:chunk_start + chunk_size]
        conditions = []
        
        for r in chunk_rows:
            market = _sq(r["MARKET"].upper())
            brand = _sq(r["BRAND"].upper())
            insight = _sq(r["INSIGHT"])
            type_val = _sq(r["TYPE"])
            value_1 = _sq(r["VALUE_1"])
            
            conditions.append(
                f"(UPPER(TRIM(MARKET)) = '{market}' AND "
                f"UPPER(TRIM(BRAND)) = '{brand}' AND "
                f"TRIM(INSIGHT) = '{insight}' AND "
                f"TRIM(TYPE) = '{type_val}' AND "
                f"TRIM(VALUE_1) = '{value_1}')"
            )
        
        sql = f"""
            SELECT UPPER(TRIM(MARKET)) as MARKET,
                   UPPER(TRIM(BRAND)) as BRAND,
                   TRIM(INSIGHT) as INSIGHT,
                   TRIM(TYPE) as TYPE,
                   TRIM(VALUE_1) as VALUE_1
            FROM {INSIGHT_TABLE}
            WHERE {' OR '.join(conditions)}
        """
        
        try:
            df = dc.execute_query(sql)
            if df is not None and not df.empty:
                for _, row in df.iterrows():
                    duplicate_set.add((
                        row['MARKET'], 
                        row['BRAND'], 
                        row['INSIGHT'],
                        row['TYPE'],
                        row['VALUE_1']
                    ))
        except Exception as e:
            print(f"Batch duplicate check error (chunk {chunk_start//chunk_size + 1}): {str(e)}")
    
    return duplicate_set

def _batch_insert_rows_brand_study(rows, added_by):
    """Batch insert for Brand Studies endpoint"""
    if not rows:
        return 0
    
    total_inserted = 0
    chunk_size = 25
    
    for chunk_start in range(0, len(rows), chunk_size):
        chunk_rows = rows[chunk_start:chunk_start + chunk_size]
        
        for r in chunk_rows:
            market_upper = r['MARKET'].upper()
            brand_upper = r['BRAND'].upper()
            
            sql = f"""
                INSERT INTO {INSIGHT_TABLE}
                    (BRAND, MARKET, INSIGHT, TYPE, VALUE_1, VALUE_2, VALUE_3, VALUE_4, ADDED_BY, ENTRY_TIME)
                VALUES
                    ('{_sq(brand_upper)}', '{_sq(market_upper)}', '{_sq(r['INSIGHT'])}', '{_sq(r['TYPE'])}',
                     '{_sq(r['VALUE_1'])}', NULL, NULL, NULL,
                     '{_sq(added_by)}', CURRENT_TIMESTAMP())
            """
            
            try:
                dc.execute_non_query(sql)
                total_inserted += 1
            except Exception as e:
                print(f"Insert error: {str(e)}")
                raise
    
    return total_inserted

def _process_template_excel_brand_study(file_obj):
    """Process Excel template for Brand Studies endpoint"""
    try:
        excel_file = pd.ExcelFile(file_obj, engine="openpyxl")
        
        if TARGET_SHEET_NAME_BRAND_STUDY not in excel_file.sheet_names:
            raise ValueError(
                f"Required sheet '{TARGET_SHEET_NAME_BRAND_STUDY}' not found. "
                f"Available sheets: {', '.join(excel_file.sheet_names)}"
            )
        
        df = pd.read_excel(
            file_obj, 
            sheet_name=TARGET_SHEET_NAME_BRAND_STUDY,
            header=HEADER_ROW_INDEX_BRAND_STUDY,
            engine="openpyxl"
        )
        
        if len(df.columns) > 0:
            df = df.iloc[:, 1:]
        
        df.columns = [str(c).strip() for c in df.columns]
        df = df.replace({pd.NA: "", None: ""}).fillna("")
        
        df['_excel_row_num'] = range(4, 4 + len(df))
        df = df[df.drop('_excel_row_num', axis=1).astype(str).apply(lambda x: x.str.strip().str.len().sum(), axis=1) > 0]
        
        available_excel_cols = set(df.columns) - {'_excel_row_num'}
        expected_excel_cols = set(EXCEL_TO_DB_MAPPING_BRAND_STUDY.keys())
        missing_cols = expected_excel_cols - available_excel_cols
        
        missing_columns_list = list(missing_cols) if missing_cols else None
        
        mandatory_excel_cols = ["Market", "Brand", "Study Name"]
        missing_mandatory = [col for col in mandatory_excel_cols if col not in df.columns]
        
        if missing_mandatory:
            raise ValueError(
                f"Missing mandatory columns in '{TARGET_SHEET_NAME_BRAND_STUDY}' sheet: {', '.join(missing_mandatory)}. "
                f"Found columns: {list(df.columns)}"
            )
        
        mapped_data = []
        
        for idx, row in df.iterrows():
            excel_row_num = int(row['_excel_row_num'])
            mapped_row = {}
            
            for excel_col, db_col in EXCEL_TO_DB_MAPPING_BRAND_STUDY.items():
                if excel_col in df.columns:
                    value = row.get(excel_col, "")
                    mapped_row[db_col] = _clean(value)
                else:
                    mapped_row[db_col] = ""
            
            mapped_row["INSIGHT"] = FIXED_INSIGHT_VALUE_BRAND_STUDY
            mapped_row["TYPE"] = FIXED_TYPE_VALUE_BRAND_STUDY
            mapped_row["VALUE_2"] = None
            mapped_row["VALUE_3"] = None
            mapped_row["VALUE_4"] = None
            
            if (mapped_row.get("MARKET") and 
                mapped_row.get("BRAND") and 
                mapped_row.get("VALUE_1")):
                mapped_data.append((excel_row_num, mapped_row))
        
        if not mapped_data:
            raise ValueError(
                f"No valid data rows found in sheet '{TARGET_SHEET_NAME_BRAND_STUDY}'. "
                f"Ensure mandatory fields (Market, Brand, Study Name) have values."
            )
        
        return mapped_data, missing_columns_list
        
    except Exception as e:
        raise Exception(f"Error processing template Excel: {str(e)}")

@app.route("/d_ffn_insight_config_brand_study", methods=["GET"])
def insight_brand_study_get():
    try:
        definitions = {
            "Description": {
                "BRAND": {
                    "Example Values": ["AREXVY", "SHINGRIX"],
                    "Description": "Name of Brand to be deployed",
                    "Parameter_type": "Mandatory"
                },
                "MARKET": {
                    "Example Values": ["GBR", "THA", "ITA", "PRT"],
                    "Description": "Name of the Market to be deployed",
                    "Parameter_type": "Mandatory"
                },
                "INSIGHT": {
                    "Example Values": ["medical-word-reassignment"],
                    "Description": "Fixed value for insight type",
                    "Parameter_type": "Auto-filled (Fixed Value)"
                },
                "TYPE": {
                    "Example Values": ["STUDY"],
                    "Description": "Fixed value for type",
                    "Parameter_type": "Auto-filled (Fixed Value)"
                },
                "VALUE_1": {
                    "Example Values": ["Key Study Name text"],
                    "Description": "The actual key Study Name content",
                    "Parameter_type": "Mandatory"
                },
                "VALUE_2": {
                    "Example Values": ["NULL"],
                    "Description": "Reserved for future use",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "VALUE_3": {
                    "Example Values": ["NULL"],
                    "Description": "Reserved for future use",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "VALUE_4": {
                    "Example Values": ["NULL"],
                    "Description": "Reserved for future use",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "ADDED_BY": {
                    "Example Values": ["abc.x.abc@gsk.com"],
                    "Description": "Auto-picked from 'Username' header in POST",
                    "Parameter_type": "Mandatory (via header)"
                },
                "ENTRY_TIME": {
                    "Example Values": ["current_timestamp()"],
                    "Description": "Set by system at insert time",
                    "Parameter_type": "Auto-generated"
                }
            },
            "sample_json": {
                "MARKET": "THA",
                "BRAND": "AREXVY",
                "VALUE_1": "This is a key Study Name"
            },
            "excel_upload_instructions": {
                "expected_extension": ".xlsx",
                "template_sheet_name": TARGET_SHEET_NAME_BRAND_STUDY,
                "header_row": HEADER_ROW_INDEX_BRAND_STUDY + 1,
                "form_field_name": "file",
                "required_columns": ["Market", "Brand", "Study Name"],
                "column_mapping": EXCEL_TO_DB_MAPPING_BRAND_STUDY,
                "fixed_values": {
                    "INSIGHT": FIXED_INSIGHT_VALUE_BRAND_STUDY,
                    "TYPE": FIXED_TYPE_VALUE_BRAND_STUDY,
                    "VALUE_2": "NULL",
                    "VALUE_3": "NULL",
                    "VALUE_4": "NULL"
                },
                "notes": [
                    "Tablename: hive_metastore.fieldforce_navigator_deployment.d_ffn_insight_config",
                    f"The Excel file must contain a sheet named '{TARGET_SHEET_NAME_BRAND_STUDY}'",
                    f"Headers must be in row {HEADER_ROW_INDEX_BRAND_STUDY + 1} of the sheet, starting from Column B",
                    "Data rows should start from row 4 onwards, Column B onwards",
                    "Column A is ignored during processing",
                    "INSIGHT and TYPE are automatically set to fixed values",
                    "VALUE_2, VALUE_3, VALUE_4 are automatically set to NULL"
                ]
            }
        }
        return jsonify(definitions), status.HTTP_200_OK
    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR

@app.route("/d_ffn_insight_config_brand_study", methods=["POST"])
def insight_brand_study_post():
    try:
        added_by = _clean(request.headers.get("Username", "") or "")
        if not added_by:
            return jsonify({"error": "Missing 'Username' in headers."}), status.HTTP_400_BAD_REQUEST

        _get_valid_markets_brands(force_refresh=True)

        rows = []
        is_excel_mode = False
        missing_columns_warning = None

        if "file" in request.files:
            is_excel_mode = True
            f = request.files["file"]
            fname = (f.filename or "").lower().strip()
            
            if not fname.endswith(".xlsx"):
                return jsonify({
                    "error": "Only .xlsx files are supported for bulk upload."
                }), status.HTTP_400_BAD_REQUEST

            try:
                rows, missing_columns_warning = _process_template_excel_brand_study(f)
                
                if not rows:
                    return jsonify({
                        "error": f"No valid data rows found in sheet '{TARGET_SHEET_NAME_BRAND_STUDY}'."
                    }), status.HTTP_400_BAD_REQUEST
                
            except ValueError as ve:
                return jsonify({"error": str(ve)}), status.HTTP_400_BAD_REQUEST
            except Exception as e:
                return jsonify({
                    "error": f"Failed to process Excel template: {str(e)}"
                }), status.HTTP_400_BAD_REQUEST

        else:
            body = request.get_json(force=True, silent=True) or {}
            items = body if isinstance(body, list) else [body]

            for i, rec in enumerate(items, start=1):
                market = _clean(rec.get("MARKET", ""))
                brand  = _clean(rec.get("BRAND", ""))
                value_1 = _clean(rec.get("VALUE_1", ""))

                if not market or not brand or not value_1:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Missing required field(s). MARKET, BRAND, and VALUE_1 are mandatory."
                    }), status.HTTP_400_BAD_REQUEST

                market_valid, brand_valid = _validate_market_brand_separately(market, brand)
                
                if not market_valid:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Invalid MARKET '{market}'. This market does not exist."
                    }), status.HTTP_400_BAD_REQUEST
                
                if not brand_valid:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Invalid BRAND '{brand}'. This brand does not exist."
                    }), status.HTTP_400_BAD_REQUEST

                rows.append((i, {
                    "MARKET": market,
                    "BRAND": brand,
                    "INSIGHT": FIXED_INSIGHT_VALUE_BRAND_STUDY,
                    "TYPE": FIXED_TYPE_VALUE_BRAND_STUDY,
                    "VALUE_1": value_1,
                    "VALUE_2": None,
                    "VALUE_3": None,
                    "VALUE_4": None
                }))

        if not rows:
            return jsonify({"error": "No valid rows to process."}), status.HTTP_400_BAD_REQUEST

        invalid_markets = []
        invalid_brands = []
        valid_rows = []
        
        valid_data = _get_valid_markets_brands()
        
        for row_num, r in rows:
            market = r["MARKET"]
            brand = r["BRAND"]
            
            market_valid = market.upper().strip() in valid_data['markets']
            brand_valid = brand.upper().strip() in valid_data['brands']
            
            if not market_valid:
                invalid_markets.append({
                    "excel_row": row_num,
                    "MARKET": market,
                    "BRAND": brand,
                    "reason": "Invalid MARKET - not found in audio_market_brand_config"
                })
                continue
            
            if not brand_valid:
                invalid_brands.append({
                    "excel_row": row_num,
                    "MARKET": market,
                    "BRAND": brand,
                    "reason": "Invalid BRAND - not found in audio_market_brand_config"
                })
                continue
            
            valid_rows.append((row_num, r))
        
        duplicate_set = _batch_check_duplicates_brand_study([r for _, r in valid_rows])
        
        duplicates = []
        insertable_rows = []
        
        for row_num, r in valid_rows:
            key = (
                r["MARKET"].upper().strip(),
                r["BRAND"].upper().strip(),
                r["INSIGHT"].strip(),
                r["TYPE"].strip(),
                r["VALUE_1"].strip()
            )
            
            if key in duplicate_set:
                duplicates.append({
                    "excel_row": row_num,
                    "MARKET": r["MARKET"],
                    "BRAND": r["BRAND"],
                    "VALUE_1": r["VALUE_1"],
                    "reason": "Duplicate - already exists in database"
                })
            else:
                insertable_rows.append(r)
        
        inserted = 0
        errors = []
        
        if insertable_rows:
            try:
                inserted = _batch_insert_rows_brand_study(insertable_rows, added_by)
            except Exception as e:
                errors.append({
                    "error": f"Batch insert failed: {str(e)}"
                })

        response = {
            "status": "success" if inserted and not errors else ("partial" if inserted else "no-change"),
            "mode": "excel-template" if is_excel_mode else "json",
            "sheet_processed": TARGET_SHEET_NAME_BRAND_STUDY if is_excel_mode else None,
            "total_rows_processed": len(rows),
            "inserted_count": inserted,
            "duplicate_count": len(duplicates),
            "validation_errors_count": len(invalid_markets) + len(invalid_brands),
            "skipped_duplicates": duplicates,
            "invalid_markets": invalid_markets,
            "invalid_brands": invalid_brands,
            "row_errors": errors
        }
        
        if is_excel_mode and missing_columns_warning:
            response["warning"] = {
                "message": "The uploaded Excel template is missing some required columns.",
                "missing_columns": missing_columns_warning,
                "note": "All three columns (Market, Brand, Study Name) are required for Insight Config."
            }
        
        response = {k: v for k, v in response.items() 
                   if v is not None and not (isinstance(v, list) and len(v) == 0)}
        
        if inserted > 0:
            status_code = status.HTTP_201_CREATED
        elif invalid_markets or invalid_brands:
            status_code = status.HTTP_207_MULTI_STATUS
        else:
            status_code = status.HTTP_200_OK
        
        return jsonify(response), status_code

    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR


