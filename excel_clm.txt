# ===================== Competitor Config – Individual Endpoint =====================

COMP_TABLE = "hive_metastore.fieldforce_navigator_deployment.d_ffn_competitor_config"

# ---- tiny helpers (same style as your MWE) ----
def _clean(s):  # trim & collapse spaces
    return " ".join(str(s).strip().split()) if s is not None else ""

def _sq(s):     # escape single quotes
    return str(s).replace("'", "''")

def _is_nullish(v):
    """Return True if value should be treated as SQL NULL."""
    if v is None:
        return True
    t = str(v).strip()
    if t == "":
        return True
    return t.lower() == "null"

def _exists_cmpt_row(market, brand, comp_brand, comp_type):
    # case-insensitive duplicate check
    sql = f"""
        SELECT 1
        FROM {COMP_TABLE}
        WHERE UPPER(TRIM(MARKET))            = UPPER(TRIM('{_sq(market)}'))
          AND UPPER(TRIM(BRAND))             = UPPER(TRIM('{_sq(brand)}'))
          AND UPPER(TRIM(COMPETITOR_BRANDS)) = UPPER(TRIM('{_sq(comp_brand)}'))
          AND UPPER(TRIM(COMPETITION_TYPE))  = UPPER(TRIM('{_sq(comp_type)}'))
        LIMIT 1
    """
    df = dc.execute_query(sql)
    return df is not None and not df.empty

def _insert_cmpt_row(market, brand, disease_state, drug_class,
                     comp_brands, comp_type, molecule, other_names,
                     combination, added_by):
    # Build NULL-aware SQL pieces for optional fields
    ds_sql  = "NULL" if _is_nullish(disease_state) else f"'{_sq(disease_state)}'"
    dc_sql  = "NULL" if _is_nullish(drug_class)    else f"'{_sq(drug_class)}'"
    mol_sql = "NULL" if _is_nullish(molecule)      else f"'{_sq(molecule)}'"
    oth_sql = "NULL" if _is_nullish(other_names)   else f"'{_sq(other_names)}'"
    cmb_sql = "NULL" if _is_nullish(combination)   else f"'{_sq(combination)}'"

    sql = f"""
        INSERT INTO {COMP_TABLE}
            (MARKET, BRAND, DISEASE_STATE, DRUG_CLASS,
             COMPETITOR_BRANDS, COMPETITION_TYPE,
             ADDED_BY, ENTRY_TIME,
             MOLECULE, OTHER_NAMES, COMBINATION)
        VALUES
            ('{_sq(market)}','{_sq(brand)}',{ds_sql},{dc_sql},
             '{_sq(comp_brands)}','{_sq(comp_type)}',
             '{_sq(added_by)}',CURRENT_TIMESTAMP(),
             {mol_sql},{oth_sql},{cmb_sql})
    """
    dc.execute_non_query(sql)

# ---------- GET: column definitions + simple post template ----------
@app.route("/d_ffn_competitor_config", methods=["GET"])
def competitor_get():
    try:
        definitions = {
            "payload": {
                # keep order as shown below (insertion order preserved on Py3.7+)
                "MARKET": {
                    "Example Values": ["GBR", "THA", "ITA", "PRT"],
                    "Description": "Market code (country/cluster).",
                    "Parameter_type": "Mandatory"
                },
                "BRAND": {
                    "Example Values": ["AREXVY", "SHINGRIX"],
                    "Description": "Brand name.",
                    "Parameter_type": "Mandatory"
                },
                "DISEASE_STATE": {
                    "Example Values": ["RSV vaccine", "Shingles"],
                    "Description": "Primary disease area or indication.",
                    "Parameter_type": "Optional"
                },
                "DRUG_CLASS": {
                    "Example Values": ["Non-adjuvanted", "Adjuvanted"],
                    "Description": "Drug class/category.",
                    "Parameter_type": "Optional"
                },
                "COMPETITOR_BRANDS": {
                    "Example Values": ["Abrysvo"],
                    "Description": "Competing brand name.",
                    "Parameter_type": "Mandatory"
                },
                "COMPETITION_TYPE": {
                    "Example Values": ["COMPETITOR", "ALTERNATIVE"],
                    "Description": "Relationship type vs our brand.",
                    "Parameter_type": "Mandatory"
                },
                "MOLECULE": {
                    "Example Values": ["RSVPreF"],
                    "Description": "Active component or molecule.",
                    "Parameter_type": "Optional"
                },
                "OTHER_NAMES": {
                    "Example Values": ["null"],
                    "Description": "Aliases / other names.",
                    "Parameter_type": "Optional"
                },
                "COMBINATION": {
                    "Example Values": ["null"],
                    "Description": "Combination component(s) if any.",
                    "Parameter_type": "Optional"
                },
                "ADDED_BY": {
                    "Example Values": ["abc.x.abc@gsk.com"],
                    "Description": "Auto-picked from 'Username' header in POST.",
                    "Parameter_type": "Mandatory (via header)"
                },
                "ENTRY_TIME": {
                    "Example Values": ["current_timestamp()"],
                    "Description": "Set by system at insert time.",
                    "Parameter_type": "Auto-generated"
                }
            },
            "post_request_template_json": {
                "MARKET": "THA",
                "BRAND": "AREXVY",
                "DISEASE_STATE": "RSV vaccine",
                "DRUG_CLASS": "Non-adjuvanted",
                "COMPETITOR_BRANDS": "Abrysvo",
                "COMPETITION_TYPE": "COMPETITOR",
                "MOLECULE": "null",
                "OTHER_NAMES": "null",
                "COMBINATION": "null"
            },
            "excel_upload_instructions": {
                "expected_extension": ".xlsx",
                "form_field_name": "file",
                "required_columns": ["MARKET", "BRAND", "COMPETITOR_BRANDS", "COMPETITION_TYPE"],
                "optional_columns": ["DISEASE_STATE", "DRUG_CLASS", "MOLECULE", "OTHER_NAMES", "COMBINATION"],
                "notes": [
                    "First row must be headers.",
                    "ADDED_BY is taken from 'Username' header.",
                    "ENTRY_TIME is auto.",
                    "Duplicate check is case-insensitive on (MARKET, BRAND, COMPETITOR_BRANDS, COMPETITION_TYPE).",
                    "Optional columns may be missing in Excel header; they will be stored as NULL if absent/blank/'null'."
                ]
            }
        }
        return jsonify(definitions), status.HTTP_200_OK
    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR

# ---------- POST: JSON (single/list) OR Excel (.xlsx) ----------
@app.route("/d_ffn_competitor_config", methods=["POST"])
def competitor_post():
    try:
        # who is inserting
        added_by = _clean(request.headers.get("Username", "") or "")
        if not added_by:
            return jsonify({"error": "Missing 'Username' in headers."}), status.HTTP_400_BAD_REQUEST

        rows = []  # list of dicts in original order

        if "file" in request.files:
            # Excel (multipart/form-data)
            f = request.files["file"]
            fname = (f.filename or "").lower().strip()
            if not fname.endswith(".xlsx"):
                return jsonify({"error": "Only .xlsx files are supported for bulk upload."}), status.HTTP_400_BAD_REQUEST

            df = pd.read_excel(f, engine="openpyxl")
            df.columns = [str(c).strip().upper() for c in df.columns]

            req = ["MARKET", "BRAND", "COMPETITOR_BRANDS", "COMPETITION_TYPE"]
            missing = [c for c in req if c not in df.columns]
            if missing:
                return jsonify({"error": f"Missing required columns in Excel: {', '.join(missing)}"}), status.HTTP_400_BAD_REQUEST

            # normalize NAs to empty strings; we'll convert to NULL downstream
            df = df.replace({pd.NA: "", None: ""}).fillna("")

            for idx, r in df.iterrows():
                # required
                market = _clean(r.get("MARKET", ""))
                brand  = _clean(r.get("BRAND", ""))
                cbrand = _clean(r.get("COMPETITOR_BRANDS", ""))
                ctype  = _clean(r.get("COMPETITION_TYPE", ""))

                if not market or not brand or not cbrand or not ctype:
                    return jsonify({
                        "status": "error",
                        "message": f"Row {int(idx)+2}: Missing MARKET/BRAND/COMPETITOR_BRANDS/COMPETITION_TYPE."
                    }), status.HTTP_400_BAD_REQUEST

                # optional (may be absent in header)
                disease = _clean(r.get("DISEASE_STATE", ""))
                dclass  = _clean(r.get("DRUG_CLASS", ""))
                molec   = _clean(r.get("MOLECULE", ""))
                other   = _clean(r.get("OTHER_NAMES", ""))
                comb    = _clean(r.get("COMBINATION", ""))

                rows.append({
                    "MARKET": market,
                    "BRAND": brand,
                    "DISEASE_STATE": disease,
                    "DRUG_CLASS": dclass,
                    "COMPETITOR_BRANDS": cbrand,
                    "COMPETITION_TYPE": ctype,
                    "MOLECULE": molec,
                    "OTHER_NAMES": other,
                    "COMBINATION": comb
                })

        else:
            # JSON (single object or list)
            body = request.get_json(force=True, silent=True) or {}
            items = body if isinstance(body, list) else [body]

            for i, rec in enumerate(items, start=1):
                market = _clean(rec.get("MARKET", ""))
                brand  = _clean(rec.get("BRAND", ""))
                cbrand = _clean(rec.get("COMPETITOR_BRANDS", ""))
                ctype  = _clean(rec.get("COMPETITION_TYPE", ""))

                if not market or not brand or not cbrand or not ctype:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Missing MARKET/BRAND/COMPETITOR_BRANDS/COMPETITION_TYPE."
                    }), status.HTTP_400_BAD_REQUEST

                disease = _clean(rec.get("DISEASE_STATE", ""))
                dclass  = _clean(rec.get("DRUG_CLASS", ""))
                molec   = _clean(rec.get("MOLECULE", "null"))      # default to "null" for JSON template
                other   = _clean(rec.get("OTHER_NAMES", "null"))
                comb    = _clean(rec.get("COMBINATION", "null"))

                rows.append({
                    "MARKET": market,
                    "BRAND": brand,
                    "DISEASE_STATE": disease,
                    "DRUG_CLASS": dclass,
                    "COMPETITOR_BRANDS": cbrand,
                    "COMPETITION_TYPE": ctype,
                    "MOLECULE": molec,
                    "OTHER_NAMES": other,
                    "COMBINATION": comb
                })

        if not rows:
            return jsonify({"error": "No valid rows to process."}), status.HTTP_400_BAD_REQUEST

        # process in order: SELECT 1 → INSERT (skip duplicates)
        inserted = 0
        duplicates = []
        errors = []

        for idx, r in enumerate(rows, start=1):
            try:
                market = r["MARKET"]
                brand  = r["BRAND"]
                cbrand = r["COMPETITOR_BRANDS"]
                ctype  = r["COMPETITION_TYPE"]

                if _exists_cmpt_row(market, brand, cbrand, ctype):
                    duplicates.append({
                        "row": idx,
                        "MARKET": market,
                        "BRAND": brand,
                        "COMPETITOR_BRANDS": cbrand,
                        "COMPETITION_TYPE": ctype,
                        "reason": "duplicate"
                    })
                    continue

                _insert_cmpt_row(
                    market=market,
                    brand=brand,
                    disease_state=r.get("DISEASE_STATE", ""),
                    drug_class=r.get("DRUG_CLASS", ""),
                    comp_brands=cbrand,
                    comp_type=ctype,
                    molecule=r.get("MOLECULE", ""),
                    other_names=r.get("OTHER_NAMES", ""),
                    combination=r.get("COMBINATION", ""),
                    added_by=added_by
                )
                inserted += 1

            except Exception as row_err:
                errors.append({
                    "row": idx,
                    "MARKET": r.get("MARKET"),
                    "BRAND": r.get("BRAND"),
                    "COMPETITOR_BRANDS": r.get("COMPETITOR_BRANDS"),
                    "COMPETITION_TYPE": r.get("COMPETITION_TYPE"),
                    "error": str(row_err)
                })

        return jsonify({
            "status": "success" if inserted and not errors else ("partial" if inserted else "no-change"),
            "mode": "excel" if "file" in request.files else "json",
            "inserted_count": inserted,
            "skipped_duplicates": duplicates,
            "row_errors": errors
        }), (status.HTTP_201_CREATED if inserted else status.HTTP_200_OK)

    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR

# ===================== end Competitor Config endpoint =====================




# ===================== MWE (Medical Words Examples) – Individual Endpoint ===================== Final Working

MWE_TABLE = "hive_metastore.fieldforce_navigator_deployment.llm_medical_words_examples"

# ---- tiny helpers ----
def _clean(s):  # trim & collapse spaces
    return " ".join(str(s).strip().split()) if s is not None else ""

def _sq(s):     # escape single quotes
    return str(s).replace("'", "''")

def _exists_mwe_row(brand, incorrect, corrected):
    # case-insensitive duplicate check (stable and simple)
    sql = f"""
        SELECT 1
        FROM {MWE_TABLE}
        WHERE UPPER(TRIM(BRAND))          = UPPER(TRIM('{_sq(brand)}'))
          AND UPPER(TRIM(INCORRECT_TERM)) = UPPER(TRIM('{_sq(incorrect)}'))
          AND UPPER(TRIM(CORRECTED_TERM)) = UPPER(TRIM('{_sq(corrected)}'))
        LIMIT 1
    """
    df = dc.execute_query(sql)
    return df is not None and not df.empty

def _insert_mwe_row(brand, incorrect, corrected, added_by):
    sql = f"""
        INSERT INTO {MWE_TABLE}
            (BRAND, INCORRECT_TERM, CORRECTED_TERM, ADDED_BY, ENTRY_TIME)
        VALUES
            ('{_sq(brand)}','{_sq(incorrect)}','{_sq(corrected)}','{_sq(added_by)}',CURRENT_TIMESTAMP())
    """
    dc.execute_non_query(sql)

# ---------- GET: column definitions + simple post template ----------
@app.route("/llm_mwe_table", methods=["GET"])
def mwe_get():
    try:
        definitions = {
            "payload": {
                # keep order as shown below (Py3.7+ preserves insertion order)
                "BRAND": {
                    "Example Values": ["SHINGRIX", "AREXVY"],
                    "Description": "Brand name.",
                    "Parameter_type": "Mandatory"
                },
                "INCORRECT_TERM": {
                    "Example Values": ["Chingrix", "Arexyv"],
                    "Description": "Misspelt or wrong medical term.",
                    "Parameter_type": "Mandatory"
                },
                "CORRECTED_TERM": {
                    "Example Values": ["Shingrix", "AREXVY"],
                    "Description": "Correct replacement term.",
                    "Parameter_type": "Mandatory"
                },
                "ADDED_BY": {
                    "Example Values": ["abc.x.abc@gsk.com"],
                    "Description": "Auto-picked from 'Username' header in POST.",
                    "Parameter_type": "Mandatory (via header)"
                },
                "ENTRY_TIME": {
                    "Example Values": ["current_timestamp()"],
                    "Description": "Set by system at insert time.",
                    "Parameter_type": "Auto-generated"
                }
            },
            "post_request_template_json": {
                "BRAND": "SHINGRIX",
                "INCORRECT_TERM": "Chingrix",
                "CORRECTED_TERM": "Shingrix"
            },
            "excel_upload_instructions": {
                "expected_extension": ".xlsx",
                "form_field_name": "file",
                "required_columns": ["BRAND", "INCORRECT_TERM", "CORRECTED_TERM"],
                "notes": [
                    "First row must be headers.",
                    "ADDED_BY is taken from 'Username' header.",
                    "ENTRY_TIME is auto.",
                    "Duplicate check is case-insensitive per row.",
                    "Rows are processed in order: check → insert or skip."
                ]
            }
        }
        return jsonify(definitions), status.HTTP_200_OK
    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR

# ---------- POST: JSON (single/list) OR Excel (.xlsx) ----------
@app.route("/llm_mwe_table", methods=["POST"])
def mwe_post():
    try:
        # who is inserting
        added_by = _clean(request.headers.get("Username", "") or "")
        if not added_by:
            return jsonify({"error": "Missing 'Username' in headers."}), status.HTTP_400_BAD_REQUEST

        rows = []  # list of (brand, incorrect, corrected) in original order

        if "file" in request.files:
            # Excel (multipart/form-data)
            f = request.files["file"]
            fname = (f.filename or "").lower().strip()
            if not fname.endswith(".xlsx"):
                return jsonify({"error": "Only .xlsx files are supported for bulk upload."}), status.HTTP_400_BAD_REQUEST

            df = pd.read_excel(f, engine="openpyxl")
            df.columns = [str(c).strip().upper() for c in df.columns]

            req = ["BRAND", "INCORRECT_TERM", "CORRECTED_TERM"]
            missing = [c for c in req if c not in df.columns]
            if missing:
                return jsonify({"error": f"Missing required columns in Excel: {', '.join(missing)}"}), status.HTTP_400_BAD_REQUEST

            df = df.replace({pd.NA: "", None: ""}).fillna("")
            for idx, r in df.iterrows():
                brand     = _clean(r.get("BRAND", ""))
                incorrect = _clean(r.get("INCORRECT_TERM", ""))
                corrected = _clean(r.get("CORRECTED_TERM", ""))
                if not brand or not incorrect or not corrected:
                    return jsonify({"status": "error",
                                    "message": f"Row {int(idx)+2}: Missing BRAND/INCORRECT_TERM/CORRECTED_TERM."}), status.HTTP_400_BAD_REQUEST
                rows.append((brand, incorrect, corrected))
        else:
            # JSON (single object or list)
            body = request.get_json(force=True, silent=True) or {}
            items = body if isinstance(body, list) else [body]
            for i, rec in enumerate(items, start=1):
                brand     = _clean(rec.get("BRAND", ""))
                incorrect = _clean(rec.get("INCORRECT_TERM", ""))
                corrected = _clean(rec.get("CORRECTED_TERM", ""))
                if not brand or not incorrect or not corrected:
                    return jsonify({"status": "error",
                                    "message": f"Item {i}: Missing BRAND/INCORRECT_TERM/CORRECTED_TERM."}), status.HTTP_400_BAD_REQUEST
                rows.append((brand, incorrect, corrected))

        if not rows:
            return jsonify({"error": "No valid rows to process."}), status.HTTP_400_BAD_REQUEST

        # process in order: SELECT 1 → INSERT (skip duplicates)
        inserted = 0
        duplicates = []
        errors = []

        for idx, (brand, incorrect, corrected) in enumerate(rows, start=1):
            try:
                if _exists_mwe_row(brand, incorrect, corrected):
                    duplicates.append({
                        "row": idx,
                        "BRAND": brand,
                        "INCORRECT_TERM": incorrect,
                        "CORRECTED_TERM": corrected,
                        "reason": "duplicate"
                    })
                    continue

                _insert_mwe_row(brand, incorrect, corrected, added_by)
                inserted += 1

            except Exception as row_err:
                errors.append({
                    "row": idx,
                    "BRAND": brand,
                    "INCORRECT_TERM": incorrect,
                    "CORRECTED_TERM": corrected,
                    "error": str(row_err)
                })

        return jsonify({
            "status": "success" if inserted and not errors else ("partial" if inserted else "no-change"),
            "mode": "excel" if "file" in request.files else "json",
            "inserted_count": inserted,
            "skipped_duplicates": duplicates,
            "row_errors": errors
        }), (status.HTTP_201_CREATED if inserted else status.HTTP_200_OK)

    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR






----------------------------------------------- Brfore Thrift Error -----------------------


# ===================== MWE (Medical Words Examples) – Individual Endpoint =====================

MWE_TABLE = "hive_metastore.fieldforce_navigator_deployment.llm_medical_words_examples"

# ---- tiny helpers (same style as before) ----
def _clean(s):  # trim & collapse spaces
    return " ".join(str(s).strip().split()) if s is not None else ""

def _sq(s):     # escape single quotes
    return str(s).replace("'", "''")

def _exists_mwe_row(brand, incorrect, corrected):
    # per-row, case-insensitive duplicate check (your earlier working pattern)
    sql = f"""
        SELECT 1
        FROM {MWE_TABLE}
        WHERE UPPER(TRIM(BRAND))          = UPPER(TRIM('{_sq(brand)}'))
          AND UPPER(TRIM(INCORRECT_TERM)) = UPPER(TRIM('{_sq(incorrect)}'))
          AND UPPER(TRIM(CORRECTED_TERM)) = UPPER(TRIM('{_sq(corrected)}'))
        LIMIT 1
    """
    df = dc.execute_query(sql)
    return df is not None and not df.empty

def _insert_mwe_row(brand, incorrect, corrected, added_by):
    sql = f"""
        INSERT INTO {MWE_TABLE}
            (BRAND, INCORRECT_TERM, CORRECTED_TERM, ADDED_BY, ENTRY_TIME)
        VALUES
            ('{_sq(brand)}','{_sq(incorrect)}','{_sq(corrected)}','{_sq(added_by)}',CURRENT_TIMESTAMP())
    """
    dc.execute_non_query(sql)

# ---------- GET: column definitions + simple post template ----------
@app.route("/llm_mwe_table", methods=["GET"])
def mwe_get():
    try:
        definitions = {
            "payload": {
                "MARKET": {  # included for visibility; MWE insert does not use it
                    "Example Values": ["GBR", "THA", "ITA", "PRT"],
                    "Description": "Market code (not used by MWE insert).",
                    "Parameter_type": "Optional"
                },
                "BRAND": {
                    "Example Values": ["SHINGRIX", "AREXVY"],
                    "Description": "Brand name.",
                    "Parameter_type": "Mandatory"
                },
                "INCORRECT_TERM": {
                    "Example Values": ["Chingrix", "Arexyv"],
                    "Description": "Misspelt or wrong medical term.",
                    "Parameter_type": "Mandatory"
                },
                "CORRECTED_TERM": {
                    "Example Values": ["Shingrix", "AREXVY"],
                    "Description": "Correct replacement term.",
                    "Parameter_type": "Mandatory"
                },
                "ADDED_BY": {
                    "Example Values": ["abc.x.abc@gsk.com"],
                    "Description": "Auto-picked from 'Username' header in POST. Ignore in body.",
                    "Parameter_type": "Mandatory (via header)"
                },
                "ENTRY_TIME": {
                    "Example Values": ["current_timestamp()"],
                    "Description": "Set by system at insert time.",
                    "Parameter_type": "Auto-generated"
                }
            },
            "post_request_template_json": {
                "BRAND": "SHINGRIX",
                "INCORRECT_TERM": "Chingrix",
                "CORRECTED_TERM": "Shingrix"
            },
            "excel_upload_instructions": {
                "expected_extension": ".xlsx",
                "form_field_name": "file",
                "required_columns": ["BRAND", "INCORRECT_TERM", "CORRECTED_TERM"],
                "notes": [
                    "First row must be headers.",
                    "ADDED_BY is taken from 'Username' header.",
                    "ENTRY_TIME is auto.",
                    "Duplicate check is case-insensitive per row.",
                    "Each row is processed independently (check then insert or skip)."
                ]
            }
        }
        return jsonify(definitions), status.HTTP_200_OK
    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR

# ---------- POST: JSON (single/many) OR Excel (.xlsx) – per-row SELECT+INSERT ----------
@app.route("/llm_mwe_table", methods=["POST"])
def mwe_post():
    try:
        # who is inserting
        added_by = _clean(request.headers.get("Username", "") or "")
        if not added_by:
            return jsonify({"error": "Missing 'Username' in headers."}), status.HTTP_400_BAD_REQUEST

        # Collect rows as (brand, incorrect, corrected) in the provided order
        rows = []

        if "file" in request.files:
            # Excel path (multipart/form-data)
            f = request.files["file"]
            fname = (f.filename or "").lower().strip()
            if not fname.endswith(".xlsx"):
                return jsonify({"error": "Only .xlsx files are supported for bulk upload."}), status.HTTP_400_BAD_REQUEST

            df = pd.read_excel(f, engine="openpyxl")
            df.columns = [str(c).strip().upper() for c in df.columns]

            req = ["BRAND", "INCORRECT_TERM", "CORRECTED_TERM"]
            missing = [c for c in req if c not in df.columns]
            if missing:
                return jsonify({"error": f"Missing required columns in Excel: {', '.join(missing)}"}), status.HTTP_400_BAD_REQUEST

            df = df.replace({pd.NA: "", None: ""}).fillna("")

            # row-by-row (keep original order from Excel)
            for idx, r in df.iterrows():
                brand     = _clean(r.get("BRAND", ""))
                incorrect = _clean(r.get("INCORRECT_TERM", ""))
                corrected = _clean(r.get("CORRECTED_TERM", ""))
                if not brand or not incorrect or not corrected:
                    return jsonify({
                        "status": "error",
                        "message": f"Row {int(idx)+2}: Missing BRAND/INCORRECT_TERM/CORRECTED_TERM."
                    }), status.HTTP_400_BAD_REQUEST
                rows.append((brand, incorrect, corrected))
        else:
            # JSON path (object or list)
            body = request.get_json(force=True, silent=True) or {}
            items = body if isinstance(body, list) else [body]
            for i, rec in enumerate(items, start=1):
                brand     = _clean(rec.get("BRAND", ""))
                incorrect = _clean(rec.get("INCORRECT_TERM", ""))
                corrected = _clean(rec.get("CORRECTED_TERM", ""))
                if not brand or not incorrect or not corrected:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Missing BRAND/INCORRECT_TERM/CORRECTED_TERM."
                    }), status.HTTP_400_BAD_REQUEST
                rows.append((brand, incorrect, corrected))

        if not rows:
            return jsonify({"error": "No valid rows to process."}), status.HTTP_400_BAD_REQUEST

        # Process one-by-one: SELECT 1 → INSERT (or skip if duplicate)
        inserted = 0
        duplicates = []
        errors = []

        for idx, (brand, incorrect, corrected) in enumerate(rows, start=1):
            try:
                if _exists_mwe_row(brand, incorrect, corrected):
                    duplicates.append({
                        "row": idx,
                        "BRAND": brand,
                        "INCORRECT_TERM": incorrect,
                        "CORRECTED_TERM": corrected,
                        "reason": "duplicate"
                    })
                    continue

                _insert_mwe_row(brand, incorrect, corrected, added_by)
                inserted += 1

            except Exception as row_err:
                errors.append({
                    "row": idx,
                    "BRAND": brand,
                    "INCORRECT_TERM": incorrect,
                    "CORRECTED_TERM": corrected,
                    "error": str(row_err)
                })

        return jsonify({
            "status": "success" if inserted and not errors else ("partial" if inserted else "no-change"),
            "mode": "excel" if "file" in request.files else "json",
            "inserted_count": inserted,
            "skipped_duplicates": duplicates,
            "row_errors": errors
        }), (status.HTTP_201_CREATED if inserted else status.HTTP_200_OK)

    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR

----------------

        SELECT *
        FROM hive_metastore.fieldforce_navigator_deployment.llm_medical_words_examples
        WHERE UPPER(TRIM(BRAND)) = UPPER(TRIM('SHINGRIX'))
          AND UPPER(TRIM(INCORRECT_TERM)) = UPPER(TRIM('Chingrix-test1sep'))
          AND UPPER(TRIM(CORRECTED_TERM)) = UPPER(TRIM('Shingrix-test1sep'))
        LIMIT 1


Executing query:

        WITH incoming(brand, incorrect_term, corrected_term) AS (
            SELECT * FROM VALUES ('SHINGRIX','Chingrix','Shingrix')
        )
        SELECT i.brand, i.incorrect_term, i.corrected_term
        FROM incoming i
        INNER JOIN hive_metastore.fieldforce_navigator_deployment.llm_medical_words_examples t
          ON UPPER(TRIM(t.BRAND))          = UPPER(TRIM(i.brand))
         AND UPPER(TRIM(t.INCORRECT_TERM)) = UPPER(TRIM(i.incorrect_term))
         AND UPPER(TRIM(t.CORRECTED_TERM)) = UPPER(TRIM(i.corrected_term))

SQL execution error: No module named 'thrift.transport.THttpClient'












BRAND	INCORRECT_TERM	CORRECTED_TERM
AREXVY	cospitalization	hospitalization
AREXVY	neutriosis	neurotoxicity
AREXVY	motiality	mortality
AREXVY	 in Monia	Pneumonia
AREXVY	 deficazy	efficacy
AREXVY	Numonia	Pneumonia
AREXVY	Aleksermo	Arexvy
AREXVY	Momoya	Moyamoya
AREXVY	 Alexvi.	Arexvy
AREXVY	Alexis 	Arexvy
AREXVY	Alexvi 	Arexvy
AREXVY	Alexis	Arexvy
AREXVY	Alexis	Arexvy
AREXVY	Alec	Arexvy
AREXVY	 full,	Flu
AREXVY	RHB	RSV
AREXVY	GFK	GSK
AREXVY	Alex V vaccine	Arexvy
AREXVY	 innospital	hospital
AREXVY	naspact	nasopharynx
AREXVY	Ijuvan	adjuvanted
AREXVY	adjoant 	adjuvant
AREXVY	nimonia	Pneumonia
AREXVY	Biolent	Bivalent
AREXVY	Angi ISV	Arexvy
AREXVY	Allevi 	Arexvy
AREXVY	Alex V 	Arexvy
AREXVY	Alexei	Arexvy
AREXVY	 Nolek	Arexvy
AREXVY	Asman	Asthma
AREXVY	AlexV	Arexvy
AREXVY	Cobic	Covid
AREXVY	Esmar 	RSV
AREXVY	R s V	RSV
AREXVY	ISP	RSV
AREXVY	RB 	RSV
AREXVY	RSB	RSV


MARKET	BRAND	DISEASE_STATE	DRUG_CLASS	COMPETITOR_BRANDS	COMPETITION_TYPE
GBR	OMJJARA	Myelofibrosis	JAK inhibitor	Fedratinib (INREBIC)	COMPETITOR
GBR	OMJJARA	Myelofibrosis	JAK inhibitor	Ruxolotinib (JAKAVI)	COMPETITOR


AREXVY	RHV	RSV



{
    "sample_json": {
        "MARKET": {
            "Example Values": [
                "GBR",
                "THA",
                "ITA",
                "PRT"
            ],
            "Description": "v",
            "Parameter_type": "Mandatory"
        },
        "BRAND": {
            "Example Values": [
                "SHINGRIX",
                "AREXVY",
                "BLENREP"
            ],
            "Description": "Brand name.",
            "Parameter_type": "Mandatory"
        },
        "DISEASE_STATE": {
            "Example Values": [
                "RSV vaccine",
                "Shingles"
            ],
            "Description": "Disease area",
            "Parameter_type": "Mandatory"
        },
        "DRUG_CLASS": {
            "Example Values": [
                "Non-adjuvanted",
                "Adjuvanted"
            ],
            "Description": "High-level category",
            "Parameter_type": "Mandatory"
        },
        "COMPETITOR_BRANDS": {
            "Example Values": [
                "Abrysvo",
                "Generic-X"
            ],
            "Description": "Competitor Brand",
            "Parameter_type": "Mandatory"
        },
        "COMPETITION_TYPE": {
            "Example Values": [
                "COMPETITOR"
            ],
            "Description": "Type of relation COMPETITOR",
            "Parameter_type": "Mandatory"
        },
        "MOLECULE": {
            "Example Values": [
                "RSVPreF"
            ],
            "Description": "molecule (if known).",
            "Parameter_type": "Optional"
        },
        "OTHER_NAMES": {
            "Example Values": [
                "null",
                "RSVPreF3",
                "Brand alias"
            ],
            "Description": "v1",
            "Parameter_type": "Optional"
        },
        "COMBINATION": {
            "Example Values": [
                "null",
                "Compound-A + Compound-B"
            ],
            "Description": "v1",
            "Parameter_type": "Optional"
        },
        "ADDED_BY": {
            "Example Values": [
                "abc.x.abc@gsk.com"
            ],
            "Description": "Your email; can also be passed via 'Username' header.",
            "Parameter_type": "Mandatory"
        }
    },
    "post_request_template": {
        "MARKET": "THA",
        "BRAND": "AREXVY",
        "DISEASE_STATE": "RSV vaccine",
        "DRUG_CLASS": "Non-adjuvanted",
        "COMPETITOR_BRANDS": "Abrysvo",
        "COMPETITION_TYPE": "COMPETITOR",
        "MOLECULE": "RSVPreF",
        "OTHER_NAMES": "null",
        "COMBINATION": "null",
        "ADDED_BY": "abc.x.abc@gsk.com"
    },
    "desc": "Copy the template, change values as needed, and POST to /competitor_config."


















# ====== MWE: Medical Words Examples (individual endpoint) ======

MWE_TABLE = "hive_metastore.fieldforce_navigator_deployment.llm_medical_words_examples"

# --- helpers (small & local) ---
def _clean(s):
    return " ".join(str(s).strip().split()) if s is not None else ""

def _sq(s):
    return str(s).replace("'", "''")

def _exists_mwe(brand, incorrect, corrected):
    sql = f"""
        SELECT 1
        FROM {MWE_TABLE}
        WHERE UPPER(TRIM(BRAND)) = UPPER(TRIM('{_sq(brand)}'))
          AND UPPER(TRIM(INCORRECT_TERM)) = UPPER(TRIM('{_sq(incorrect)}'))
          AND UPPER(TRIM(CORRECTED_TERM)) = UPPER(TRIM('{_sq(corrected)}'))
        LIMIT 1
    """
    df = dc.execute_query(sql)
    return df is not None and not df.empty

def _insert_mwe(brand, incorrect, corrected, added_by):
    sql = f"""
        INSERT INTO {MWE_TABLE}
            (BRAND, INCORRECT_TERM, CORRECTED_TERM, ADDED_BY, ENTRY_TIME)
        VALUES
            ('{_sq(brand)}','{_sq(incorrect)}','{_sq(corrected)}','{_sq(added_by)}',CURRENT_TIMESTAMP())
    """
    dc.execute_non_query(sql)

# ---------- GET: definitions + post template ----------
@app.route("/llm_mwe_table", methods=["GET"])
def mwe_get():
    try:
        # Ordered, readable definitions
        definitions = {
            "payload": {
                "BRAND": {
                    "Example Values": ["SHINGRIX", "AREXVY"],
                    "Description": "Brand name.",
                    "Parameter_type": "Mandatory"
                },
                "INCORRECT_TERM": {
                    "Example Values": ["Chingrix", "Arexyv"],
                    "Description": "Misspelt or wrong medical term.",
                    "Parameter_type": "Mandatory"
                },
                "CORRECTED_TERM": {
                    "Example Values": ["Shingrix", "AREXVY"],
                    "Description": "Correct replacement term.",
                    "Parameter_type": "Mandatory"
                },
                "ADDED_BY": {
                    "Example Values": ["abc.x.abc@gsk.com"],
                    "Description": "Auto-picked from 'Username' header in POST. You can ignore in body.",
                    "Parameter_type": "Mandatory (via header)"
                },
                "ENTRY_TIME": {
                    "Example Values": ["current_timestamp()"],
                    "Description": "Set by system at insert time.",
                    "Parameter_type": "Auto-generated"
                }
            },
            "post_request_template_json": {
                "BRAND": "SHINGRIX",
                "INCORRECT_TERM": "Chingrix",
                "CORRECTED_TERM": "Shingrix"
                # ADDED_BY comes from header 'Username'
                # ENTRY_TIME is auto
            },
            "excel_upload_instructions": {
                "expected_extension": ".xlsx",
                "form_field_name": "file",
                "required_columns": ["BRAND", "INCORRECT_TERM", "CORRECTED_TERM"],
                "notes": [
                    "First row must be headers.",
                    "ADDED_BY is taken from 'Username' header.",
                    "ENTRY_TIME is auto.",
                    "All duplicate checks are case-insensitive.",
                    "If any row fails validation, nothing is inserted."
                ]
            }
        }
        return jsonify(definitions), status.HTTP_200_OK
    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR

# ---------- POST: single JSON OR bulk Excel upload ----------
@app.route("/llm_mwe_table", methods=["POST"])
def mwe_post():
    try:
        # get ADDED_BY from header only (as required)
        added_by = _clean(request.headers.get("Username", "") or "")
        if not added_by:
            return jsonify({"error": "Missing 'Username' in headers."}), status.HTTP_400_BAD_REQUEST

        # Branch 1: Excel upload (multipart/form-data with key 'file')
        if "file" in request.files:
            f = request.files["file"]
            filename = (f.filename or "").lower().strip()
            if not filename.endswith(".xlsx"):
                return jsonify({"error": "Only .xlsx files are supported for bulk upload."}), status.HTTP_400_BAD_REQUEST

            # Read Excel
            df = pd.read_excel(f, engine="openpyxl")
            # Normalize headers to UPPER for matching
            df.columns = [str(c).strip().upper() for c in df.columns]

            required = ["BRAND", "INCORRECT_TERM", "CORRECTED_TERM"]
            missing_cols = [c for c in required if c not in df.columns]
            if missing_cols:
                return jsonify({"error": f"Missing required columns in Excel: {', '.join(missing_cols)}"}), status.HTTP_400_BAD_REQUEST

            # Clean rows & validate all first
            errors = []
            records = []
            seen_in_file = set()

            # Coerce NaNs to empty
            df = df.replace({pd.NA: "", None: ""}).fillna("")

            for idx, row in df.iterrows():
                brand     = _clean(row.get("BRAND", ""))
                incorrect = _clean(row.get("INCORRECT_TERM", ""))
                corrected = _clean(row.get("CORRECTED_TERM", ""))

                row_num = int(idx) + 2  # +2 because headers are row 1

                # row-level required checks
                if not brand or not incorrect or not corrected:
                    errors.append({"row": row_num, "error": "Missing one of: BRAND, INCORRECT_TERM, CORRECTED_TERM"})
                    continue

                key = (brand.upper(), incorrect.upper(), corrected.upper())
                if key in seen_in_file:
                    errors.append({"row": row_num, "error": "Duplicate row in file (case-insensitive)."})
                    continue
                seen_in_file.add(key)

                # DB duplicate pre-check
                if _exists_mwe(brand, incorrect, corrected):
                    errors.append({
                        "row": row_num,
                        "error": "Duplicate in database (case-insensitive).",
                        "conflict_on": {"BRAND": brand, "INCORRECT_TERM": incorrect, "CORRECTED_TERM": corrected}
                    })
                    continue

                records.append((brand, incorrect, corrected))

            if errors:
                return jsonify({
                    "status": "error",
                    "message": "Validation failed. No rows inserted.",
                    "errors": errors
                }), status.HTTP_409_CONFLICT

            # All good → insert all
            for brand, incorrect, corrected in records:
                _insert_mwe(brand, incorrect, corrected, added_by)

            return jsonify({
                "status": "success",
                "mode": "excel",
                "inserted_count": len(records)
            }), status.HTTP_201_CREATED

        # Branch 2: JSON single (or list) record(s)
        body = request.get_json(force=True, silent=True) or {}
        # allow a single dict or a list of dicts
        if isinstance(body, dict):
            items = [body]
        elif isinstance(body, list):
            items = body
        else:
            return jsonify({"error": "Body must be a JSON object or a list of objects."}), status.HTTP_400_BAD_REQUEST

        # Validate all first
        errors = []
        records = []
        seen_in_payload = set()

        for i, rec in enumerate(items, start=1):
            brand     = _clean(rec.get("BRAND", ""))
            incorrect = _clean(rec.get("INCORRECT_TERM", ""))
            corrected = _clean(rec.get("CORRECTED_TERM", ""))

            if not brand or not incorrect or not corrected:
                errors.append({"item": i, "error": "Missing one of: BRAND, INCORRECT_TERM, CORRECTED_TERM"})
                continue

            key = (brand.upper(), incorrect.upper(), corrected.upper())
            if key in seen_in_payload:
                errors.append({"item": i, "error": "Duplicate record in payload (case-insensitive)."})
                continue
            seen_in_payload.add(key)

            if _exists_mwe(brand, incorrect, corrected):
                errors.append({
                    "item": i,
                    "error": "Duplicate in database (case-insensitive).",
                    "conflict_on": {"BRAND": brand, "INCORRECT_TERM": incorrect, "CORRECTED_TERM": corrected}
                })
                continue

            records.append((brand, incorrect, corrected))

        if errors:
            return jsonify({
                "status": "error",
                "message": "Validation failed. No records inserted.",
                "errors": errors
            }), status.HTTP_409_CONFLICT

        # Insert all
        for brand, incorrect, corrected in records:
            _insert_mwe(brand, incorrect, corrected, added_by)

        return jsonify({
            "status": "success",
            "mode": "json",
            "inserted_count": len(records)
        }), status.HTTP_201_CREATED

    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR

}





# ====== MWE: Medical Words Examples (individual endpoint, batched checks/inserts) ======

MWE_TABLE = "hive_metastore.fieldforce_navigator_deployment.llm_medical_words_examples"

# --- helpers ---
def _clean(s):
    return " ".join(str(s).strip().split()) if s is not None else ""

def _sq(s):
    return str(s).replace("'", "''")

def _values_block(rows3):
    """
    Build a VALUES block like:
      VALUES ('A','B','C'),('D','E','F')
    where rows3 = [(brand, incorrect, corrected), ...]
    """
    if not rows3:
        return "VALUES"  # not used if empty
    parts = []
    for b, i, c in rows3:
        parts.append(f"('{_sq(b)}','{_sq(i)}','{_sq(c)}')")
    return "VALUES " + ",".join(parts)

def _find_conflicts_mwe(rows3):
    """
    Single batched check: returns list of (brand, incorrect, corrected) already present in DB.
    Case-insensitive & trim on both sides.
    """
    vals = _values_block(rows3)
    sql = f"""
        WITH incoming(brand, incorrect_term, corrected_term) AS (
            SELECT * FROM {vals}
        )
        SELECT i.brand, i.incorrect_term, i.corrected_term
        FROM incoming i
        INNER JOIN {MWE_TABLE} t
          ON UPPER(TRIM(t.BRAND))          = UPPER(TRIM(i.brand))
         AND UPPER(TRIM(t.INCORRECT_TERM)) = UPPER(TRIM(i.incorrect_term))
         AND UPPER(TRIM(t.CORRECTED_TERM)) = UPPER(TRIM(i.corrected_term))
    """
    df = dc.execute_query(sql)
    if df is None or df.empty:
        return []
    # normalize to tuples of strings
    out = []
    for _, r in df.iterrows():
        out.append((str(r[0]), str(r[1]), str(r[2])))
    return out

def _insert_batch_mwe(rows3, added_by):
    """
    Single batched INSERT using SELECT FROM VALUES → no per-row inserts.
    """
    vals = _values_block(rows3)
    sql = f"""
        INSERT INTO {MWE_TABLE}
            (BRAND, INCORRECT_TERM, CORRECTED_TERM, ADDED_BY, ENTRY_TIME)
        SELECT brand, incorrect_term, corrected_term, '{_sq(added_by)}', CURRENT_TIMESTAMP()
        FROM {vals} AS v(brand, incorrect_term, corrected_term)
    """
    dc.execute_non_query(sql)

# ---------- GET: definitions + post template ----------
@app.route("/llm_mwe_table", methods=["GET"])
def mwe_get():
    try:
        definitions = {
            "payload": {
                "BRAND": {
                    "Example Values": ["SHINGRIX", "AREXVY"],
                    "Description": "Brand name.",
                    "Parameter_type": "Mandatory"
                },
                "INCORRECT_TERM": {
                    "Example Values": ["Chingrix", "Arexyv"],
                    "Description": "Misspelt or wrong medical term.",
                    "Parameter_type": "Mandatory"
                },
                "CORRECTED_TERM": {
                    "Example Values": ["Shingrix", "AREXVY"],
                    "Description": "Correct replacement term.",
                    "Parameter_type": "Mandatory"
                },
                "ADDED_BY": {
                    "Example Values": ["abc.x.abc@gsk.com"],
                    "Description": "Auto-picked from 'Username' header in POST. Ignore in body.",
                    "Parameter_type": "Mandatory (via header)"
                },
                "ENTRY_TIME": {
                    "Example Values": ["current_timestamp()"],
                    "Description": "Set by system at insert time.",
                    "Parameter_type": "Auto-generated"
                }
            },
            "post_request_template_json": {
                "BRAND": "SHINGRIX",
                "INCORRECT_TERM": "Chingrix",
                "CORRECTED_TERM": "Shingrix"
            },
            "excel_upload_instructions": {
                "expected_extension": ".xlsx",
                "form_field_name": "file",
                "required_columns": ["BRAND", "INCORRECT_TERM", "CORRECTED_TERM"],
                "notes": [
                    "First row must be headers.",
                    "ADDED_BY is taken from 'Username' header.",
                    "ENTRY_TIME is auto.",
                    "All duplicate checks are case-insensitive.",
                    "If any row fails validation, nothing is inserted."
                ]
            }
        }
        return jsonify(definitions), status.HTTP_200_OK
    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR

# ---------- POST: single JSON OR bulk Excel upload (batched DB round-trips) ----------
@app.route("/llm_mwe_table", methods=["POST"])
def mwe_post():
    try:
        added_by = _clean(request.headers.get("Username", "") or "")
        if not added_by:
            return jsonify({"error": "Missing 'Username' in headers."}), status.HTTP_400_BAD_REQUEST

        rows = []  # to collect (brand, incorrect, corrected)

        # A) Excel path (multipart/form-data)
        if "file" in request.files:
            f = request.files["file"]
            filename = (f.filename or "").lower().strip()
            if not filename.endswith(".xlsx"):
                return jsonify({"error": "Only .xlsx files are supported for bulk upload."}), status.HTTP_400_BAD_REQUEST

            df = pd.read_excel(f, engine="openpyxl")
            df.columns = [str(c).strip().upper() for c in df.columns]

            req_cols = ["BRAND", "INCORRECT_TERM", "CORRECTED_TERM"]
            miss_cols = [c for c in req_cols if c not in df.columns]
            if miss_cols:
                return jsonify({"error": f"Missing required columns in Excel: {', '.join(miss_cols)}"}), status.HTTP_400_BAD_REQUEST

            df = df.replace({pd.NA: "", None: ""}).fillna("")

            # Clean + collect
            for idx, r in df.iterrows():
                brand     = _clean(r.get("BRAND", ""))
                incorrect = _clean(r.get("INCORRECT_TERM", ""))
                corrected = _clean(r.get("CORRECTED_TERM", ""))
                if not brand or not incorrect or not corrected:
                    return jsonify({
                        "status": "error",
                        "message": f"Row {int(idx)+2}: Missing one of BRAND/INCORRECT_TERM/CORRECTED_TERM."
                    }), status.HTTP_400_BAD_REQUEST
                rows.append((brand, incorrect, corrected))

        else:
            # B) JSON path (object or list of objects)
            body = request.get_json(force=True, silent=True) or {}
            items = body if isinstance(body, list) else [body]
            for i, rec in enumerate(items, start=1):
                brand     = _clean(rec.get("BRAND", ""))
                incorrect = _clean(rec.get("INCORRECT_TERM", ""))
                corrected = _clean(rec.get("CORRECTED_TERM", ""))
                if not brand or not incorrect or not corrected:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Missing one of BRAND/INCORRECT_TERM/CORRECTED_TERM."
                    }), status.HTTP_400_BAD_REQUEST
                rows.append((brand, incorrect, corrected))

        if not rows:
            return jsonify({"error": "No valid rows to insert."}), status.HTTP_400_BAD_REQUEST

        # In-payload/file dedup (case-insensitive)
        seen = set()
        deduped = []
        for b, i, c in rows:
            k = (b.upper(), i.upper(), c.upper())
            if k not in seen:
                seen.add(k)
                deduped.append((b, i, c))

        # Single batched duplicate check against DB
        conflicts = _find_conflicts_mwe(deduped)
        if conflicts:
            # return all conflicts, no inserts
            conflict_list = [
                {"BRAND": b, "INCORRECT_TERM": i, "CORRECTED_TERM": c}
                for (b, i, c) in conflicts
            ]
            return jsonify({
                "status": "error",
                "message": "Duplicate(s) exist in database. Nothing inserted.",
                "conflicts": conflict_list
            }), status.HTTP_409_CONFLICT

        # Single batched INSERT
        _insert_batch_mwe(deduped, added_by)

        return jsonify({
            "status": "success",
            "mode": "excel" if "file" in request.files else "json",
            "inserted_count": len(deduped)
        }), status.HTTP_201_CREATED

    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR






--------------------------------------------------------------



# ====== MWE: Medical Words Examples (individual endpoint, batched checks/inserts) ======

MWE_TABLE = "hive_metastore.fieldforce_navigator_deployment.llm_medical_words_examples"

# --- helpers ---
def _clean(s):
    return " ".join(str(s).strip().split()) if s is not None else ""

def _sq(s):
    return str(s).replace("'", "''")

def _values_block(rows3):
    """
    Build a VALUES block like:
      VALUES ('A','B','C'),('D','E','F')
    where rows3 = [(brand, incorrect, corrected), ...]
    """
    if not rows3:
        return "VALUES"  # not used if empty
    parts = []
    for b, i, c in rows3:
        parts.append(f"('{_sq(b)}','{_sq(i)}','{_sq(c)}')")
    return "VALUES " + ",".join(parts)

def _find_conflicts_mwe(rows3):
    """
    Single batched check: returns list of (brand, incorrect, corrected) already present in DB.
    Case-insensitive & trim on both sides.
    """
    vals = _values_block(rows3)
    sql = f"""
        WITH incoming(brand, incorrect_term, corrected_term) AS (
            SELECT * FROM {vals}
        )
        SELECT i.brand, i.incorrect_term, i.corrected_term
        FROM incoming i
        INNER JOIN {MWE_TABLE} t
          ON UPPER(TRIM(t.BRAND))          = UPPER(TRIM(i.brand))
         AND UPPER(TRIM(t.INCORRECT_TERM)) = UPPER(TRIM(i.incorrect_term))
         AND UPPER(TRIM(t.CORRECTED_TERM)) = UPPER(TRIM(i.corrected_term))
    """
    df = dc.execute_query(sql)
    if df is None or df.empty:
        return []
    # normalize to tuples of strings
    out = []
    for _, r in df.iterrows():
        out.append((str(r[0]), str(r[1]), str(r[2])))
    return out

def _insert_batch_mwe(rows3, added_by):
    """
    Single batched INSERT using SELECT FROM VALUES → no per-row inserts.
    """
    vals = _values_block(rows3)
    sql = f"""
        INSERT INTO {MWE_TABLE}
            (BRAND, INCORRECT_TERM, CORRECTED_TERM, ADDED_BY, ENTRY_TIME)
        SELECT brand, incorrect_term, corrected_term, '{_sq(added_by)}', CURRENT_TIMESTAMP()
        FROM {vals} AS v(brand, incorrect_term, corrected_term)
    """
    dc.execute_non_query(sql)

# ---------- GET: definitions + post template ----------
@app.route("/llm_mwe_table", methods=["GET"])
def mwe_get():
    try:
        definitions = {
            "payload": {
                "BRAND": {
                    "Example Values": ["SHINGRIX", "AREXVY"],
                    "Description": "Brand name.",
                    "Parameter_type": "Mandatory"
                },
                "INCORRECT_TERM": {
                    "Example Values": ["Chingrix", "Arexyv"],
                    "Description": "Misspelt or wrong medical term.",
                    "Parameter_type": "Mandatory"
                },
                "CORRECTED_TERM": {
                    "Example Values": ["Shingrix", "AREXVY"],
                    "Description": "Correct replacement term.",
                    "Parameter_type": "Mandatory"
                },
                "ADDED_BY": {
                    "Example Values": ["abc.x.abc@gsk.com"],
                    "Description": "Auto-picked from 'Username' header in POST. Ignore in body.",
                    "Parameter_type": "Mandatory (via header)"
                },
                "ENTRY_TIME": {
                    "Example Values": ["current_timestamp()"],
                    "Description": "Set by system at insert time.",
                    "Parameter_type": "Auto-generated"
                }
            },
            "post_request_template_json": {
                "BRAND": "SHINGRIX",
                "INCORRECT_TERM": "Chingrix",
                "CORRECTED_TERM": "Shingrix"
            },
            "excel_upload_instructions": {
                "expected_extension": ".xlsx",
                "form_field_name": "file",
                "required_columns": ["BRAND", "INCORRECT_TERM", "CORRECTED_TERM"],
                "notes": [
                    "First row must be headers.",
                    "ADDED_BY is taken from 'Username' header.",
                    "ENTRY_TIME is auto.",
                    "All duplicate checks are case-insensitive.",
                    "If any row fails validation, nothing is inserted."
                ]
            }
        }
        return jsonify(definitions), status.HTTP_200_OK
    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR

# ---------- POST: single JSON OR bulk Excel upload (batched DB round-trips) ----------
@app.route("/llm_mwe_table", methods=["POST"])
def mwe_post():
    try:
        added_by = _clean(request.headers.get("Username", "") or "")
        if not added_by:
            return jsonify({"error": "Missing 'Username' in headers."}), status.HTTP_400_BAD_REQUEST

        rows = []  # to collect (brand, incorrect, corrected)

        # A) Excel path (multipart/form-data)
        if "file" in request.files:
            f = request.files["file"]
            filename = (f.filename or "").lower().strip()
            if not filename.endswith(".xlsx"):
                return jsonify({"error": "Only .xlsx files are supported for bulk upload."}), status.HTTP_400_BAD_REQUEST

            df = pd.read_excel(f, engine="openpyxl")
            df.columns = [str(c).strip().upper() for c in df.columns]

            req_cols = ["BRAND", "INCORRECT_TERM", "CORRECTED_TERM"]
            miss_cols = [c for c in req_cols if c not in df.columns]
            if miss_cols:
                return jsonify({"error": f"Missing required columns in Excel: {', '.join(miss_cols)}"}), status.HTTP_400_BAD_REQUEST

            df = df.replace({pd.NA: "", None: ""}).fillna("")

            # Clean + collect
            for idx, r in df.iterrows():
                brand     = _clean(r.get("BRAND", ""))
                incorrect = _clean(r.get("INCORRECT_TERM", ""))
                corrected = _clean(r.get("CORRECTED_TERM", ""))
                if not brand or not incorrect or not corrected:
                    return jsonify({
                        "status": "error",
                        "message": f"Row {int(idx)+2}: Missing one of BRAND/INCORRECT_TERM/CORRECTED_TERM."
                    }), status.HTTP_400_BAD_REQUEST
                rows.append((brand, incorrect, corrected))

        else:
            # B) JSON path (object or list of objects)
            body = request.get_json(force=True, silent=True) or {}
            items = body if isinstance(body, list) else [body]
            for i, rec in enumerate(items, start=1):
                brand     = _clean(rec.get("BRAND", ""))
                incorrect = _clean(rec.get("INCORRECT_TERM", ""))
                corrected = _clean(rec.get("CORRECTED_TERM", ""))
                if not brand or not incorrect or not corrected:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Missing one of BRAND/INCORRECT_TERM/CORRECTED_TERM."
                    }), status.HTTP_400_BAD_REQUEST
                rows.append((brand, incorrect, corrected))

        if not rows:
            return jsonify({"error": "No valid rows to insert."}), status.HTTP_400_BAD_REQUEST

        # In-payload/file dedup (case-insensitive)
        seen = set()
        deduped = []
        for b, i, c in rows:
            k = (b.upper(), i.upper(), c.upper())
            if k not in seen:
                seen.add(k)
                deduped.append((b, i, c))

        # Single batched duplicate check against DB
        conflicts = _find_conflicts_mwe(deduped)
        if conflicts:
            # return all conflicts, no inserts
            conflict_list = [
                {"BRAND": b, "INCORRECT_TERM": i, "CORRECTED_TERM": c}
                for (b, i, c) in conflicts
            ]
            return jsonify({
                "status": "error",
                "message": "Duplicate(s) exist in database. Nothing inserted.",
                "conflicts": conflict_list
            }), status.HTTP_409_CONFLICT

        # Single batched INSERT
        _insert_batch_mwe(deduped, added_by)

        return jsonify({
            "status": "success",
            "mode": "excel" if "file" in request.files else "json",
            "inserted_count": len(deduped)
        }), status.HTTP_201_CREATED

    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR

