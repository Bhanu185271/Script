INSIGHT_TABLE = "hive_metastore.fieldforce_navigator_deployment.d_ffn_insight_config"

EXCEL_TO_DB_MAPPING_KEY_MSG = {
    "Market": "MARKET",
    "Brand": "BRAND",
    "Message": "VALUE_1"
}

FIXED_INSIGHT_VALUE_KEY_MSG = "mkt-key-messages-categorization-insight"
FIXED_TYPE_VALUE_KEY_MSG = "Market_Intelligence"
TARGET_SHEET_NAME_KEY_MSG = "Brand - Key Messages"

def _process_template_excel_key_msg(file_obj):
    try:
        excel_file = pd.ExcelFile(file_obj, engine="openpyxl")
        
        if TARGET_SHEET_NAME_KEY_MSG not in excel_file.sheet_names:
            raise ValueError(f"Sheet '{TARGET_SHEET_NAME_KEY_MSG}' not found")
        
        df = pd.read_excel(file_obj, sheet_name=TARGET_SHEET_NAME_KEY_MSG, header=HEADER_ROW_INDEX, engine="openpyxl")
        
        if len(df.columns) > 0:
            df = df.iloc[:, 1:]
        
        df.columns = [str(c).strip() for c in df.columns]
        df = df.replace({pd.NA: "", None: ""}).fillna("")
        
        df['_excel_row_num'] = range(4, 4 + len(df))
        df = df[df.drop('_excel_row_num', axis=1).astype(str).apply(lambda x: x.str.strip().str.len().sum(), axis=1) > 0]
        
        mandatory_cols = ["Market", "Brand", "Message"]
        missing = [col for col in mandatory_cols if col not in df.columns]
        
        if missing:
            raise ValueError(f"Missing columns: {', '.join(missing)}")
        
        mapped_data = []
        
        for idx, row in df.iterrows():
            excel_row_num = int(row['_excel_row_num'])
            mapped_row = {}
            
            for excel_col, db_col in EXCEL_TO_DB_MAPPING_KEY_MSG.items():
                if excel_col in df.columns:
                    mapped_row[db_col] = _clean(row.get(excel_col, ""))
                else:
                    mapped_row[db_col] = ""
            
            mapped_row["INSIGHT"] = FIXED_INSIGHT_VALUE_KEY_MSG
            mapped_row["TYPE"] = FIXED_TYPE_VALUE_KEY_MSG
            
            if mapped_row.get("MARKET") and mapped_row.get("BRAND") and mapped_row.get("VALUE_1"):
                mapped_data.append((excel_row_num, mapped_row))
        
        return mapped_data, None
        
    except Exception as e:
        raise Exception(f"Error processing Excel: {str(e)}")

@app.route("/d_ffn_insight_config_key_msg", methods=["GET"])
def insight_key_msg_get():
    try:
        # Get brand and market from query parameters (Postman Params)
        brand_param = request.args.get("BRAND", "").strip()
        market_param = request.args.get("MARKET", "").strip()
        
        definitions = {
            "Description": {
                "BRAND": {
                    "Example Values": ["AREXVY", "SHINGRIX"],
                    "Description": "Name of Brand to be deployed",
                    "Parameter_type": "Mandatory"
                },
                "MARKET": {
                    "Example Values": ["GBR", "THA", "ITA", "PRT"],
                    "Description": "Name of the Market to be deployed",
                    "Parameter_type": "Mandatory"
                },
                "INSIGHT": {
                    "Example Values": ["mkt-key-messages-categorization-insight"],
                    "Description": "value for insight type",
                    "Parameter_type": "Mandatory : Auto-filled"
                },
                "TYPE": {
                    "Example Values": ["Market_Intelligence"],
                    "Description": "value for Insight type",
                    "Parameter_type": "Mandatory : Auto-filled"
                },
                "VALUE_1": {
                    "Example Values": ["Key Message Text"],
                    "Description": "The actual Message Text content",
                    "Parameter_type": "Mandatory"
                },
                "VALUE_2": {
                    "Example Values": ["NULL"],
                    "Description": "Value for VALUE_2 Insight Type",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "VALUE_3": {
                    "Example Values": ["NULL"],
                    "Description": "Value for VALUE_3 Insight Type",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "VALUE_4": {
                    "Example Values": ["NULL"],
                    "Description": "Value for VALUE_4 Insight Type",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "ADDED_BY": {
                    "Example Values": ["abc.x.abc@gsk.com"],
                    "Description": "Auto-picked from 'Username' header in POST",
                    "Parameter_type": "Mandatory (via header)"
                },
                "ENTRY_TIME": {
                    "Example Values": ["current_timestamp()"],
                    "Description": "Set by system at insert time",
                    "Parameter_type": "Auto-generated"
                }
            },               
                                 
            
            "sample_json": {
                "MARKET": "THA",
                "BRAND": "AREXVY",
                "INSIGHT": "mkt-key-messages-categorization-insight",
                "TYPE": "Market_Intelligence",
                "VALUE_1": "Key message text"
            }
        }
        
        # Build query with optional WHERE clause based on parameters
        query = f"SELECT * FROM {INSIGHT_TABLE}"
        where_conditions = []
        
        if brand_param:
            where_conditions.append(f"UPPER(TRIM(BRAND)) = '{_sq(brand_param.upper())}'")
        
        if market_param:
            where_conditions.append(f"UPPER(TRIM(MARKET)) = '{_sq(market_param.upper())}'")
        
        # Add filter for key messages
        where_conditions.append(f"TRIM(INSIGHT) = '{FIXED_INSIGHT_VALUE_KEY_MSG}'")
        
        if where_conditions:
            query += " WHERE " + " AND ".join(where_conditions)
        
        query += " LIMIT 1"
        
        print(f"Executing query: {query}")
        
        # Execute query to get sample data
        sample_df = dc.execute_query(query)
        
        # Initialize table_output as None
        table_output = None
        
        # If data exists, convert to JSON key-value pairs
        if sample_df is not None and not sample_df.empty:
            # Get the first row
            row = sample_df.iloc[0]
            
            # Convert row to dictionary, handling None/NaN values
            table_output = {}
            for col in sample_df.columns:
                value = row[col]
                # Convert NaN, None, or empty strings to None for cleaner JSON
                if pd.isna(value) or value == "" or str(value).strip().lower() == "null":
                    table_output[col] = None
                else:
                    table_output[col] = str(value)
        
        # Build response with table_output nested
        response = {
            "Description": definitions["Description"],
            "sample_json": definitions["sample_json"],
            "table_output": table_output
        }
        
        return jsonify(response), status.HTTP_200_OK
        
    except Exception as e:
        import traceback
        print("ERROR:", traceback.format_exc())
        return jsonify({"error": f"Internal error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR

@app.route("/d_ffn_insight_config_key_msg", methods=["POST"])
def insight_key_msg_post():
    try:
        added_by = _clean(request.headers.get("Username", "") or "")
        if not added_by:
            return jsonify({"error": "Missing Username"}), status.HTTP_400_BAD_REQUEST

        page = int(request.args.get("page", 1))
        limit = int(request.args.get("limit", 50))
        offset = (page - 1) * limit

        valid_markets_brands = _get_valid_markets_brands(force_refresh=True)

        rows = []
        is_excel_mode = False

        if "file" in request.files:
            is_excel_mode = True
            f = request.files["file"]
            
            if not (f.filename or "").lower().endswith(".xlsx"):
                return jsonify({"error": "Only .xlsx files"}), status.HTTP_400_BAD_REQUEST

            try:
                rows, _ = _process_template_excel_key_msg(f)
            except Exception as e:
                return jsonify({"error": str(e)}), status.HTTP_400_BAD_REQUEST
        else:
            body = request.get_json(force=True, silent=True) or {}
            items = body if isinstance(body, list) else [body]

            for i, rec in enumerate(items, start=1):
                market = _clean(rec.get("MARKET", ""))
                brand = _clean(rec.get("BRAND", ""))
                value_1 = _clean(rec.get("VALUE_1", ""))

                if not market or not brand or not value_1:
                    return jsonify({"error": f"Item {i}: Missing fields"}), status.HTTP_400_BAD_REQUEST

                rows.append((i, {
                    "MARKET": market,
                    "BRAND": brand,
                    "INSIGHT": FIXED_INSIGHT_VALUE_KEY_MSG,
                    "TYPE": FIXED_TYPE_VALUE_KEY_MSG,
                    "VALUE_1": value_1
                }))

        if not rows:
            return jsonify({"error": "No rows"}), status.HTTP_400_BAD_REQUEST

        # vectorized validation
        all_markets = {r[1]["MARKET"].upper() for r in rows}
        all_brands = {r[1]["BRAND"].upper() for r in rows}

        valid_market_set = {m.upper() for m in valid_markets_brands.get("markets", [])}
        valid_brand_set = {b.upper() for b in valid_markets_brands.get("brands", [])}

        invalid_mkts = [{"MARKET": m} for m in all_markets if m not in valid_market_set]
        invalid_brnds = [{"BRAND": b} for b in all_brands if b not in valid_brand_set]

        if invalid_mkts or invalid_brnds:
            return jsonify({"status": "error", "invalid_markets": invalid_mkts, "invalid_brands": invalid_brnds}), status.HTTP_400_BAD_REQUEST

        # batch duplicate check
        check_vals = []
        for r in rows:
            row_data = r[1]
            check_vals.append(
                f"(UPPER(TRIM(MARKET)) = '{_sq(row_data['MARKET'].upper())}' AND "
                f"UPPER(TRIM(BRAND)) = '{_sq(row_data['BRAND'].upper())}' AND "
                f"TRIM(INSIGHT) = '{_sq(row_data['INSIGHT'])}' AND "
                f"TRIM(TYPE) = '{_sq(row_data['TYPE'])}' AND "
                f"TRIM(VALUE_1) = '{_sq(row_data['VALUE_1'])}')"
            )

        check_query = f"""
            SELECT UPPER(TRIM(MARKET)) as MARKET, UPPER(TRIM(BRAND)) as BRAND,
                   TRIM(INSIGHT) as INSIGHT, TRIM(TYPE) as TYPE, TRIM(VALUE_1) as VALUE_1
            FROM {INSIGHT_TABLE}
            WHERE {' OR '.join(check_vals)}
        """
        
        existing = dc.execute_query(check_query)
        existing_set = set()
        if existing is not None and not existing.empty:
            for _, row in existing.iterrows():
                existing_set.add((row['MARKET'], row['BRAND'], row['INSIGHT'], row['TYPE'], row['VALUE_1']))

        inserted_rows, duplicates, errors = [], [], []
        batch_inserts = []

        for r in rows:
            try:
                row_num, row_data = r
                market = row_data["MARKET"].upper()
                brand = row_data["BRAND"].upper()
                
                key = (market, brand, row_data["INSIGHT"], row_data["TYPE"], row_data["VALUE_1"])

                if key in existing_set:
                    duplicates.append({"excel_row": row_num, "MARKET": market, "BRAND": brand})
                    continue

                batch_inserts.append(
                    f"('{_sq(brand)}', '{_sq(market)}', '{_sq(row_data['INSIGHT'])}', '{_sq(row_data['TYPE'])}', "
                    f"'{_sq(row_data['VALUE_1'])}', NULL, NULL, NULL, '{_sq(added_by)}', CURRENT_TIMESTAMP())"
                )

                inserted_rows.append({"excel_row": row_num, "MARKET": market, "BRAND": brand})

            except Exception as e:
                errors.append({"excel_row": row_num, "error": str(e)})

        # batch insert
        if batch_inserts:
            insert_query = f"""
                INSERT INTO {INSIGHT_TABLE}
                (BRAND, MARKET, INSIGHT, TYPE, VALUE_1, VALUE_2, VALUE_3, VALUE_4, ADDED_BY, ENTRY_TIME)
                VALUES {','.join(batch_inserts)}
            """
            dc.execute_non_query(insert_query)

        # pagination
        total_rows = len(rows)
        total_pages = math.ceil(total_rows / limit)
        start, end = offset, min(offset + limit, total_rows)

        response = {
            "status": "success" if inserted_rows else "no-change",
            "mode": "excel-template" if is_excel_mode else "json",
            "page": page,
            "limit": limit,
            "total_rows": total_rows,
            "total_pages": total_pages,
            "inserted_count": len(inserted_rows),
            "duplicate_count": len(duplicates),
            "inserted_rows": inserted_rows[start:end],
            "duplicates": duplicates[start:end],
            "errors": errors[start:end]
        }

        response = {k: v for k, v in response.items() if v is not None and not (isinstance(v, list) and len(v) == 0)}

        return jsonify(response), status.HTTP_201_CREATED if inserted_rows else status.HTTP_200_OK

    except Exception as e:
        import traceback
        print("ERROR:", traceback.format_exc())
        return jsonify({"error": f"Internal error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR


###############################################
# ENDPOINT 2: KEY OBJECTIONS (Optimized)
###############################################

EXCEL_TO_DB_MAPPING_KEY_OBJ = {
    "Market": "MARKET",
    "Brand": "BRAND",
    "Objection": "VALUE_1"
}

FIXED_INSIGHT_VALUE_KEY_OBJ = "mkt-objections-categorization-insight"
FIXED_TYPE_VALUE_KEY_OBJ = "Market_Intelligence"
TARGET_SHEET_NAME_KEY_OBJ = "Brand - Objections & Handlers"

def _process_template_excel_key_obj(file_obj):
    try:
        excel_file = pd.ExcelFile(file_obj, engine="openpyxl")
        
        if TARGET_SHEET_NAME_KEY_OBJ not in excel_file.sheet_names:
            raise ValueError(f"Sheet '{TARGET_SHEET_NAME_KEY_OBJ}' not found")
        
        df = pd.read_excel(file_obj, sheet_name=TARGET_SHEET_NAME_KEY_OBJ, header=HEADER_ROW_INDEX, engine="openpyxl")
        
        if len(df.columns) > 0:
            df = df.iloc[:, 1:]
        
        df.columns = [str(c).strip() for c in df.columns]
        df = df.replace({pd.NA: "", None: ""}).fillna("")
        
        df['_excel_row_num'] = range(4, 4 + len(df))
        df = df[df.drop('_excel_row_num', axis=1).astype(str).apply(lambda x: x.str.strip().str.len().sum(), axis=1) > 0]
        
        mandatory_cols = ["Market", "Brand", "Objection"]
        missing = [col for col in mandatory_cols if col not in df.columns]
        
        if missing:
            raise ValueError(f"Missing columns: {', '.join(missing)}")
        
        mapped_data = []
        
        for idx, row in df.iterrows():
            excel_row_num = int(row['_excel_row_num'])
            mapped_row = {}
            
            for excel_col, db_col in EXCEL_TO_DB_MAPPING_KEY_OBJ.items():
                if excel_col in df.columns:
                    mapped_row[db_col] = _clean(row.get(excel_col, ""))
                else:
                    mapped_row[db_col] = ""
            
            mapped_row["INSIGHT"] = FIXED_INSIGHT_VALUE_KEY_OBJ
            mapped_row["TYPE"] = FIXED_TYPE_VALUE_KEY_OBJ
            
            if mapped_row.get("MARKET") and mapped_row.get("BRAND") and mapped_row.get("VALUE_1"):
                mapped_data.append((excel_row_num, mapped_row))
        
        return mapped_data, None
        
    except Exception as e:
        raise Exception(f"Error processing Excel: {str(e)}")

@app.route("/d_ffn_insight_config_key_obj", methods=["GET"])
def insight_key_obj_get():
    try:
        # Get brand and market from query parameters (Postman Params)
        brand_param = request.args.get("BRAND", "").strip()
        market_param = request.args.get("MARKET", "").strip()
        
        definitions = {
            "Description": {
                "BRAND": {
                    "Example Values": ["AREXVY", "SHINGRIX"],
                    "Description": "Name of Brand to be deployed",
                    "Parameter_type": "Mandatory"
                },
                "MARKET": {
                    "Example Values": ["GBR", "THA", "ITA", "PRT"],
                    "Description": "Name of the Market to be deployed",
                    "Parameter_type": "Mandatory"
                },
                "INSIGHT": {
                    "Example Values": ["mkt-objections-categorization-insight"],
                    "Description": "value for insight type",
                    "Parameter_type": "Mandatory : Auto-filled"
                },
                "TYPE": {
                    "Example Values": ["Market_Intelligence"],
                    "Description": "value for Insight type",
                    "Parameter_type": "Mandatory : Auto-filled"
                },
                "VALUE_1": {
                    "Example Values": ["Key Objection Text"],
                    "Description": "The actual objection text content",
                    "Parameter_type": "Mandatory"
                },
                "VALUE_2": {
                    "Example Values": ["NULL"],
                    "Description": "Value for VALUE_2 Insight Type",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "VALUE_3": {
                    "Example Values": ["NULL"],
                    "Description": "Value for VALUE_3 Insight Type",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "VALUE_4": {
                    "Example Values": ["NULL"],
                    "Description": "Value for VALUE_4 Insight Type",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "ADDED_BY": {
                    "Example Values": ["abc.x.abc@gsk.com"],
                    "Description": "Auto-picked from 'Username' header in POST",
                    "Parameter_type": "Mandatory (via header)"
                },
                "ENTRY_TIME": {
                    "Example Values": ["current_timestamp()"],
                    "Description": "Set by system at insert time",
                    "Parameter_type": "Auto-generated"
                }
            },               
                                 
            
            "sample_json": {
                "MARKET": "THA",
                "BRAND": "AREXVY",
                "INSIGHT": "mkt-objections-categorization-insight",
                "TYPE": "Market_Intelligence",
                "VALUE_1": "Key Objection text"
            }
        }
        
        # Build query with optional WHERE clause based on parameters
        query = f"SELECT * FROM {INSIGHT_TABLE}"
        where_conditions = []
        
        if brand_param:
            where_conditions.append(f"UPPER(TRIM(BRAND)) = '{_sq(brand_param.upper())}'")
        
        if market_param:
            where_conditions.append(f"UPPER(TRIM(MARKET)) = '{_sq(market_param.upper())}'")
        
        # Add filter for key objections
        where_conditions.append(f"TRIM(INSIGHT) = '{FIXED_INSIGHT_VALUE_KEY_OBJ}'")
        
        if where_conditions:
            query += " WHERE " + " AND ".join(where_conditions)
        
        query += " LIMIT 1"
        
        print(f"Executing query: {query}")
        
        # Execute query to get sample data
        sample_df = dc.execute_query(query)
        
        # Initialize table_output as None
        table_output = None
        
        # If data exists, convert to JSON key-value pairs
        if sample_df is not None and not sample_df.empty:
            # Get the first row
            row = sample_df.iloc[0]
            
            # Convert row to dictionary, handling None/NaN values
            table_output = {}
            for col in sample_df.columns:
                value = row[col]
                # Convert NaN, None, or empty strings to None for cleaner JSON
                if pd.isna(value) or value == "" or str(value).strip().lower() == "null":
                    table_output[col] = None
                else:
                    table_output[col] = str(value)
        
        # Build response with table_output nested
        response = {
            "Description": definitions["Description"],
            "sample_json": definitions["sample_json"],
            "table_output": table_output
        }
        
        return jsonify(response), status.HTTP_200_OK
        
    except Exception as e:
        import traceback
        print("ERROR:", traceback.format_exc())
        return jsonify({"error": f"Internal error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR

@app.route("/d_ffn_insight_config_key_obj", methods=["POST"])
def insight_key_obj_post():
    try:
        added_by = _clean(request.headers.get("Username", "") or "")
        if not added_by:
            return jsonify({"error": "Missing Username"}), status.HTTP_400_BAD_REQUEST

        page = int(request.args.get("page", 1))
        limit = int(request.args.get("limit", 50))
        offset = (page - 1) * limit

        valid_markets_brands = _get_valid_markets_brands(force_refresh=True)

        rows = []
        is_excel_mode = False

        if "file" in request.files:
            is_excel_mode = True
            f = request.files["file"]
            
            if not (f.filename or "").lower().endswith(".xlsx"):
                return jsonify({"error": "Only .xlsx files"}), status.HTTP_400_BAD_REQUEST

            try:
                rows, _ = _process_template_excel_key_obj(f)
            except Exception as e:
                return jsonify({"error": str(e)}), status.HTTP_400_BAD_REQUEST
        else:
            body = request.get_json(force=True, silent=True) or {}
            items = body if isinstance(body, list) else [body]

            for i, rec in enumerate(items, start=1):
                market = _clean(rec.get("MARKET", ""))
                brand = _clean(rec.get("BRAND", ""))
                value_1 = _clean(rec.get("VALUE_1", ""))

                if not market or not brand or not value_1:
                    return jsonify({"error": f"Item {i}: Missing fields"}), status.HTTP_400_BAD_REQUEST

                rows.append((i, {
                    "MARKET": market,
                    "BRAND": brand,
                    "INSIGHT": FIXED_INSIGHT_VALUE_KEY_OBJ,
                    "TYPE": FIXED_TYPE_VALUE_KEY_OBJ,
                    "VALUE_1": value_1
                }))

        if not rows:
            return jsonify({"error": "No rows"}), status.HTTP_400_BAD_REQUEST

        # vectorized validation
        all_markets = {r[1]["MARKET"].upper() for r in rows}
        all_brands = {r[1]["BRAND"].upper() for r in rows}

        valid_market_set = {m.upper() for m in valid_markets_brands.get("markets", [])}
        valid_brand_set = {b.upper() for b in valid_markets_brands.get("brands", [])}

        invalid_mkts = [{"MARKET": m} for m in all_markets if m not in valid_market_set]
        invalid_brnds = [{"BRAND": b} for b in all_brands if b not in valid_brand_set]

        if invalid_mkts or invalid_brnds:
            return jsonify({"status": "error", "invalid_markets": invalid_mkts, "invalid_brands": invalid_brnds}), status.HTTP_400_BAD_REQUEST

        # batch duplicate check
        check_vals = []
        for r in rows:
            row_data = r[1]
            check_vals.append(
                f"(UPPER(TRIM(MARKET)) = '{_sq(row_data['MARKET'].upper())}' AND "
                f"UPPER(TRIM(BRAND)) = '{_sq(row_data['BRAND'].upper())}' AND "
                f"TRIM(INSIGHT) = '{_sq(row_data['INSIGHT'])}' AND "
                f"TRIM(TYPE) = '{_sq(row_data['TYPE'])}' AND "
                f"TRIM(VALUE_1) = '{_sq(row_data['VALUE_1'])}')"
            )

        check_query = f"""
            SELECT UPPER(TRIM(MARKET)) as MARKET, UPPER(TRIM(BRAND)) as BRAND,
                   TRIM(INSIGHT) as INSIGHT, TRIM(TYPE) as TYPE, TRIM(VALUE_1) as VALUE_1
            FROM {INSIGHT_TABLE}
            WHERE {' OR '.join(check_vals)}
        """
        
        existing = dc.execute_query(check_query)
        existing_set = set()
        if existing is not None and not existing.empty:
            for _, row in existing.iterrows():
                existing_set.add((row['MARKET'], row['BRAND'], row['INSIGHT'], row['TYPE'], row['VALUE_1']))

        inserted_rows, duplicates, errors = [], [], []
        batch_inserts = []

        for r in rows:
            try:
                row_num, row_data = r
                market = row_data["MARKET"].upper()
                brand = row_data["BRAND"].upper()
                
                key = (market, brand, row_data["INSIGHT"], row_data["TYPE"], row_data["VALUE_1"])

                if key in existing_set:
                    duplicates.append({"excel_row": row_num, "MARKET": market, "BRAND": brand})
                    continue

                batch_inserts.append(
                    f"('{_sq(brand)}', '{_sq(market)}', '{_sq(row_data['INSIGHT'])}', '{_sq(row_data['TYPE'])}', "
                    f"'{_sq(row_data['VALUE_1'])}', NULL, NULL, NULL, '{_sq(added_by)}', CURRENT_TIMESTAMP())"
                )

                inserted_rows.append({"excel_row": row_num, "MARKET": market, "BRAND": brand})

            except Exception as e:
                errors.append({"excel_row": row_num, "error": str(e)})

        # batch insert
        if batch_inserts:
            insert_query = f"""
                INSERT INTO {INSIGHT_TABLE}
                (BRAND, MARKET, INSIGHT, TYPE, VALUE_1, VALUE_2, VALUE_3, VALUE_4, ADDED_BY, ENTRY_TIME)
                VALUES {','.join(batch_inserts)}
            """
            dc.execute_non_query(insert_query)

        # pagination
        total_rows = len(rows)
        total_pages = math.ceil(total_rows / limit)
        start, end = offset, min(offset + limit, total_rows)

        response = {
            "status": "success" if inserted_rows else "no-change",
            "mode": "excel-template" if is_excel_mode else "json",
            "page": page,
            "limit": limit,
            "total_rows": total_rows,
            "total_pages": total_pages,
            "inserted_count": len(inserted_rows),
            "duplicate_count": len(duplicates),
            "inserted_rows": inserted_rows[start:end],
            "duplicates": duplicates[start:end],
            "errors": errors[start:end]
        }

        response = {k: v for k, v in response.items() if v is not None and not (isinstance(v, list) and len(v) == 0)}

        return jsonify(response), status.HTTP_201_CREATED if inserted_rows else status.HTTP_200_OK

    except Exception as e:
        import traceback
        print("ERROR:", traceback.format_exc())
        return jsonify({"error": f"Internal error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR
