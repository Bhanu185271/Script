
# Competitor Config â€“ Individual Endpoint 

COMP_TABLE = f"hive_metastore.{os.environ['schema']}.d_ffn_competitor_config"
MARKET_BRAND_TABLE = f"hive_metastore.{os.environ['schema']}.audio_market_brand_config"

# Cache for valid markets and brands 
_valid_markets_brands_cache = None
_cache_timestamp = None

import time
from datetime import datetime, timedelta

def _clean(s):  
    return " ".join(str(s).strip().split()) if s is not None else ""

def _sq(s):     
    return str(s).replace("'", "''")

def _is_nullish(v):
    """Return True if value should be treated as SQL NULL."""
    if v is None:
        return True
    t = str(v).strip()
    if t == "":
        return True
    return t.lower() == "null"

def _get_valid_markets_brands(force_refresh=False):
    """
    Get valid markets and brands from audio_market_brand_config table.
    Cache the results to avoid repeated queries.
    Returns a dict with 'markets' and 'brands' sets.
    """
    global _valid_markets_brands_cache, _cache_timestamp
    
    # Refresh cache every 5 minutes or on force_refresh
    cache_duration = timedelta(minutes=5)
    current_time = datetime.now()
    
    if (not force_refresh and 
        _valid_markets_brands_cache is not None and 
        _cache_timestamp is not None and 
        current_time - _cache_timestamp < cache_duration):
        return _valid_markets_brands_cache
    
    try:
        # Query distinct markets and brands
        sql = f"""
            SELECT 
                DISTINCT UPPER(TRIM(MARKET)) as MARKET,
                UPPER(TRIM(BRAND)) as BRAND
            FROM {MARKET_BRAND_TABLE}
            WHERE MARKET IS NOT NULL AND BRAND IS NOT NULL
        """
        
        df = dc.execute_query(sql)
        
        if df is not None and not df.empty:
            # lookup
            valid_markets = set(df['MARKET'].dropna().unique())
            valid_brands = set(df['BRAND'].dropna().unique())
            
            # Also create a set of valid combinations
            valid_combinations = set()
            for _, row in df.iterrows():
                if pd.notna(row['MARKET']) and pd.notna(row['BRAND']):
                    valid_combinations.add((row['MARKET'], row['BRAND']))
            
            _valid_markets_brands_cache = {
                'markets': valid_markets,
                'brands': valid_brands,
                'combinations': valid_combinations
            }
            _cache_timestamp = current_time
        else:
            # Empty table or query failed
            _valid_markets_brands_cache = {
                'markets': set(),
                'brands': set(),
                'combinations': set()
            }
            _cache_timestamp = current_time
            
    except Exception as e:
        print(f"Error fetching valid markets/brands: {str(e)}")
        # Return empty sets on error
        return {'markets': set(), 'brands': set(), 'combinations': set()}
    
    return _valid_markets_brands_cache

def _validate_market_brand_separately(market, brand):
    """
    Check if market AND brand exist separately in the audio_market_brand_config table
    """
    valid_data = _get_valid_markets_brands()
    
    market_upper = market.upper().strip()
    brand_upper = brand.upper().strip()
    
    market_valid = market_upper in valid_data['markets']
    brand_valid = brand_upper in valid_data['brands']
    
    return market_valid, brand_valid

def _validate_market_brand_combination(market, brand):
    """
    Check if the specific market-brand combination exists in audio_market_brand_config table.
    """
    valid_data = _get_valid_markets_brands()
    
    market_upper = market.upper().strip()
    brand_upper = brand.upper().strip()
    
    return (market_upper, brand_upper) in valid_data['combinations']

def _exists_cmpt_row(market, brand, comp_brand, comp_type):
    # case-insensitive duplicate check
    sql = f"""
        SELECT *
        FROM {COMP_TABLE}
        WHERE UPPER(TRIM(MARKET))            = UPPER(TRIM('{_sq(market)}'))
          AND UPPER(TRIM(BRAND))             = UPPER(TRIM('{_sq(brand)}'))
          AND UPPER(TRIM(COMPETITOR_BRANDS)) = UPPER(TRIM('{_sq(comp_brand)}'))
          AND UPPER(TRIM(COMPETITION_TYPE))  = UPPER(TRIM('{_sq(comp_type)}'))
        LIMIT 1
    """
    df = dc.execute_query(sql)
    return df is not None and not df.empty

def _insert_cmpt_row(market, brand, disease_state, drug_class,
                     comp_brands, comp_type, molecule, other_names,
                     combination, added_by):
    
    
    mol_sql = "NULL" if _is_nullish(molecule)      else f"'{_sq(molecule)}'"
    oth_sql = "NULL" if _is_nullish(other_names)   else f"'{_sq(other_names)}'"
    cmb_sql = "NULL" if _is_nullish(combination)   else f"'{_sq(combination)}'"

    sql = f"""
        INSERT INTO {COMP_TABLE}
            (MARKET, BRAND, DISEASE_STATE, DRUG_CLASS,
             COMPETITOR_BRANDS, COMPETITION_TYPE,
             ADDED_BY, ENTRY_TIME,
             MOLECULE, OTHER_NAMES, COMBINATION)
        VALUES
            ('{_sq(market)}','{_sq(brand)}','{_sq(disease_state)}','{_sq(drug_class)}',
             '{_sq(comp_brands)}','{_sq(comp_type)}',
             '{_sq(added_by)}',CURRENT_TIMESTAMP(),
             {mol_sql},{oth_sql},{cmb_sql})
    """
    dc.execute_non_query(sql)

# GET: column definitions + simple post template 
@app.route("/d_ffn_competitor_config", methods=["GET"])
def competitor_get():
    try:
        # Optionally, include valid markets and brands in the response
        valid_data = _get_valid_markets_brands()
        
        definitions = {
            "Description": {
                "MARKET": {
                    "Example Values": ["GBR", "THA", "ITA", "PRT"],
                    "Description": "Market country code",
                    "Parameter_type": "Mandatory"
                    
                },
                "BRAND": {
                    "Example Values": ["AREXVY", "SHINGRIX"],
                    "Description": "Brand name",
                    "Parameter_type": "Mandatory"
            
                },
                "DISEASE_STATE": {
                    "Example Values": ["RSV vaccine", "Shingles"],
                    "Description": "Primary disease area or indication",
                    "Parameter_type": "Mandatory"
                },
                "DRUG_CLASS": {
                    "Example Values": ["Non-adjuvanted", "Adjuvanted"],
                    "Description": "Drug class/category",
                    "Parameter_type": "Mandatory"
                },
                "COMPETITOR_BRANDS": {
                    "Example Values": ["Abrysvo"],
                    "Description": "Competing brand name",
                    "Parameter_type": "Mandatory"
                },
                "COMPETITION_TYPE": {
                    "Example Values": ["COMPETITOR", "ALTERNATIVE"],
                    "Description": "Relationship type vs our brand",
                    "Parameter_type": "Mandatory"
                },
                "MOLECULE": {
                    "Example Values": ["RSVPreF"],
                    "Description": "Active component or molecule",
                    "Parameter_type": "Optional"
                },
                "OTHER_NAMES": {
                    "Example Values": ["null"],
                    "Description": "Aliases / other names",
                    "Parameter_type": "Optional"
                },
                "COMBINATION": {
                    "Example Values": ["null"],
                    "Description": "Combination component if any",
                    "Parameter_type": "Optional"
                },
                "ADDED_BY": {
                    "Example Values": ["abc.x.abc@gsk.com"],
                    "Description": "Auto-picked from 'Username' header in POST",
                    "Parameter_type": "Mandatory (via header)"
                },
                "ENTRY_TIME": {
                    "Example Values": ["current_timestamp()"],
                    "Description": "Set by system at insert time",
                    "Parameter_type": "Auto-generated"
                }
            },
            "sample_json": {
                "MARKET": "THA",
                "BRAND": "AREXVY",
                "DISEASE_STATE": "RSV vaccine",
                "DRUG_CLASS": "Non-adjuvanted",
                "COMPETITOR_BRANDS": "Abrysvo",
                "COMPETITION_TYPE": "COMPETITOR",
                "MOLECULE": "null",
                "OTHER_NAMES": "null",
                "COMBINATION": "null"
            },
            "excel_upload_instructions": {
                "expected_extension": ".xlsx",
                "form_field_name": "file",
                "required_columns": ["MARKET", "BRAND", "DISEASE_STATE", "DRUG_CLASS", "COMPETITOR_BRANDS", "COMPETITION_TYPE"],
                "optional_columns": ["MOLECULE", "OTHER_NAMES", "COMBINATION"],
                "notes": [
                    "Tablename : hive_metastore.fieldforce_navigator_deployment.d_ffn_competitor_config",
                    "If you have data for optional columns, Kindly Insert the value in post request template",
                    "When optional columns are not included in the post request Excel file, the system will automatically save them as NULL (empty)"
                ]
            },
            # # Optionally include valid values for reference
            # "valid_markets": sorted(list(valid_data['markets'])) if valid_data['markets'] else [],
            # "valid_brands": sorted(list(valid_data['brands'])) if valid_data['brands'] else []
        }
        return jsonify(definitions), status.HTTP_200_OK
    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR
'''
# POST: JSON (single/list) OR Excel (.xlsx) 
@app.route("/d_ffn_competitor_config", methods=["POST"])
def competitor_post():
    try:
        # capture inserting user
        added_by = _clean(request.headers.get("Username", "") or "")
        if not added_by:
            return jsonify({"error": "Missing 'Username' in headers."}), status.HTTP_400_BAD_REQUEST

        # Refresh cache at the start of POST request to get latest valid values
        _get_valid_markets_brands(force_refresh=True)

        rows = []  # list of dicts

        if "file" in request.files:
            # Excel (multipart/form-data)
            f = request.files["file"]
            fname = (f.filename or "").lower().strip()
            if not fname.endswith(".xlsx"):
                return jsonify({"error": "Only .xlsx files are supported for bulk upload."}), status.HTTP_400_BAD_REQUEST

            df = pd.read_excel(f, engine="openpyxl")
            df.columns = [str(c).strip().upper() for c in df.columns]

            # Updated required columns to include DISEASE_STATE and DRUG_CLASS
            req = ["MARKET", "BRAND", "DISEASE_STATE", "DRUG_CLASS", "COMPETITOR_BRANDS", "COMPETITION_TYPE"]
            missing = [c for c in req if c not in df.columns]
            if missing:
                return jsonify({"error": f"Missing required columns in Excel: {', '.join(missing)}"}), status.HTTP_400_BAD_REQUEST

            # normalize NAs to empty strings
            df = df.replace({pd.NA: "", None: ""}).fillna("")

            for idx, r in df.iterrows():
                # All mandatory fields
                market = _clean(r.get("MARKET", ""))
                brand  = _clean(r.get("BRAND", ""))
                disease = _clean(r.get("DISEASE_STATE", ""))
                dclass  = _clean(r.get("DRUG_CLASS", ""))
                cbrand = _clean(r.get("COMPETITOR_BRANDS", ""))
                ctype  = _clean(r.get("COMPETITION_TYPE", ""))

                # Check all mandatory fields
                if not market or not brand or not disease or not dclass or not cbrand or not ctype:
                    return jsonify({
                        "status": "error",
                        "message": f"Row {int(idx)+2}: Missing required field(s). All of MARKET, BRAND, DISEASE_STATE, DRUG_CLASS, COMPETITOR_BRANDS, and COMPETITION_TYPE are mandatory."
                    }), status.HTTP_400_BAD_REQUEST

                # Validate MARKET and BRAND separately
                market_valid, brand_valid = _validate_market_brand_separately(market, brand)
                
                if not market_valid:
                    return jsonify({
                        "status": "error",
                        "message": f"Row {int(idx)+2}: Invalid MARKET '{market}'. This market does not exist."
                    }), status.HTTP_400_BAD_REQUEST
                
                if not brand_valid:
                    return jsonify({
                        "status": "error",
                        "message": f"Row {int(idx)+2}: Invalid BRAND '{brand}'. This brand does not exist."
                    }), status.HTTP_400_BAD_REQUEST

                # Optional: Also check if the combination exists (uncomment if needed)
                # if not _validate_market_brand_combination(market, brand):
                #     return jsonify({
                #         "status": "error",
                #         "message": f"Row {int(idx)+2}: The combination of MARKET '{market}' and BRAND '{brand}' does not exist in audio_market_brand_config table."
                #     }), status.HTTP_400_BAD_REQUEST

                # optional columns
                molec   = _clean(r.get("MOLECULE", ""))
                other   = _clean(r.get("OTHER_NAMES", ""))
                comb    = _clean(r.get("COMBINATION", ""))

                rows.append({
                    "MARKET": market,
                    "BRAND": brand,
                    "DISEASE_STATE": disease,
                    "DRUG_CLASS": dclass,
                    "COMPETITOR_BRANDS": cbrand,
                    "COMPETITION_TYPE": ctype,
                    "MOLECULE": molec,
                    "OTHER_NAMES": other,
                    "COMBINATION": comb
                })

        else:
            # JSON (single object or list)
            body = request.get_json(force=True, silent=True) or {}
            items = body if isinstance(body, list) else [body]

            for i, rec in enumerate(items, start=1):
                market = _clean(rec.get("MARKET", ""))
                brand  = _clean(rec.get("BRAND", ""))
                disease = _clean(rec.get("DISEASE_STATE", ""))
                dclass  = _clean(rec.get("DRUG_CLASS", ""))
                cbrand = _clean(rec.get("COMPETITOR_BRANDS", ""))
                ctype  = _clean(rec.get("COMPETITION_TYPE", ""))

                # Check all mandatory fields
                if not market or not brand or not disease or not dclass or not cbrand or not ctype:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Missing required field(s). All of MARKET, BRAND, DISEASE_STATE, DRUG_CLASS, COMPETITOR_BRANDS, and COMPETITION_TYPE are mandatory."
                    }), status.HTTP_400_BAD_REQUEST

                # Validate MARKET and BRAND separately
                market_valid, brand_valid = _validate_market_brand_separately(market, brand)
                
                if not market_valid:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Invalid MARKET '{market}'. This market does not exist."
                    }), status.HTTP_400_BAD_REQUEST
                
                if not brand_valid:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Invalid BRAND '{brand}'. This brand does not exist."
                    }), status.HTTP_400_BAD_REQUEST

                # Optional: Also check if the combination exists (uncomment if needed)
                # if not _validate_market_brand_combination(market, brand):
                #     return jsonify({
                #         "status": "error",
                #         "message": f"Item {i}: The combination of MARKET '{market}' and BRAND '{brand}' does not exist in audio_market_brand_config table."
                #     }), status.HTTP_400_BAD_REQUEST

                # optional columns
                molec   = _clean(rec.get("MOLECULE", "null"))      # default to "null" for JSON template
                other   = _clean(rec.get("OTHER_NAMES", "null"))
                comb    = _clean(rec.get("COMBINATION", "null"))

                rows.append({
                    "MARKET": market,
                    "BRAND": brand,
                    "DISEASE_STATE": disease,
                    "DRUG_CLASS": dclass,
                    "COMPETITOR_BRANDS": cbrand,
                    "COMPETITION_TYPE": ctype,
                    "MOLECULE": molec,
                    "OTHER_NAMES": other,
                    "COMBINATION": comb
                })

        if not rows:
            return jsonify({"error": "No valid rows to process."}), status.HTTP_400_BAD_REQUEST

        # process in order: SELECT & INSERT (skip duplicates)
        inserted = 0
        duplicates = []
        errors = []
        invalid_markets = []
        invalid_brands = []

        for idx, r in enumerate(rows, start=1):
            try:
                market = r["MARKET"]
                brand  = r["BRAND"]
                cbrand = r["COMPETITOR_BRANDS"]
                ctype  = r["COMPETITION_TYPE"]

                # Additional validation for batch processing
                market_valid, brand_valid = _validate_market_brand_separately(market, brand)
                
                if not market_valid:
                    invalid_markets.append({
                        "row": idx,
                        "MARKET": market,
                        "reason": f"MARKET not found in audio_market_brand_config"
                    })
                    continue
                
                if not brand_valid:
                    invalid_brands.append({
                        "row": idx,
                        "BRAND": brand,
                        "reason": f"BRAND not found in audio_market_brand_config"
                    })
                    continue

                if _exists_cmpt_row(market, brand, cbrand, ctype):
                    duplicates.append({
                        "row": idx,
                        "MARKET": market,
                        "BRAND": brand,
                        "COMPETITOR_BRANDS": cbrand,
                        "COMPETITION_TYPE": ctype,
                        "reason": "duplicate"
                    })
                    continue

                _insert_cmpt_row(
                    market=market,
                    brand=brand,
                    disease_state=r.get("DISEASE_STATE", ""),
                    drug_class=r.get("DRUG_CLASS", ""),
                    comp_brands=cbrand,
                    comp_type=ctype,
                    molecule=r.get("MOLECULE", ""),
                    other_names=r.get("OTHER_NAMES", ""),
                    combination=r.get("COMBINATION", ""),
                    added_by=added_by
                )
                inserted += 1

            except Exception as row_err:
                errors.append({
                    "row": idx,
                    "MARKET": r.get("MARKET"),
                    "BRAND": r.get("BRAND"),
                    "COMPETITOR_BRANDS": r.get("COMPETITOR_BRANDS"),
                    "COMPETITION_TYPE": r.get("COMPETITION_TYPE"),
                    "error": str(row_err)
                })

        response = {
            "status": "success" if inserted and not errors else ("partial" if inserted else "no-change"),
            "mode": "excel" if "file" in request.files else "json",
            "inserted_count": inserted,
            "duplicate_count": len(duplicates),
            "skipped_duplicates": duplicates,
            "invalid_markets": invalid_markets,
            "invalid_brands": invalid_brands,
            "row_errors": errors
        }
        
        # Remove empty lists from response 
        response = {k: v for k, v in response.items() if not (isinstance(v, list) and len(v) == 0)}
        
        return jsonify(response), (status.HTTP_201_CREATED if inserted else status.HTTP_200_OK)

    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR
    '''


@app.route("/d_ffn_competitor_config", methods=["POST"])
def competitor_post():
    try:
        import math

        # Capture inserting user
        added_by = _clean(request.headers.get("Username", "") or "")
        if not added_by:
            return jsonify({"error": "Missing 'Username' in headers."}), status.HTTP_400_BAD_REQUEST

        # Pagination params for response
        page = int(request.args.get("page", 1))
        limit = int(request.args.get("limit", 50))
        offset = (page - 1) * limit

        # Refresh market/brand cache for validation
        valid_markets_brands = _get_valid_markets_brands(force_refresh=True)

        # Extract request input (Excel or JSON)
        rows = []
        if "file" in request.files:
            f = request.files["file"]
            fname = (f.filename or "").lower().strip()
            if not fname.endswith(".xlsx"):
                return jsonify({"error": "Only .xlsx files are supported for bulk upload."}), status.HTTP_400_BAD_REQUEST

            df = pd.read_excel(f, engine="openpyxl")
            df.columns = [str(c).strip().upper() for c in df.columns]
            req = ["MARKET", "BRAND", "DISEASE_STATE", "DRUG_CLASS", "COMPETITOR_BRANDS", "COMPETITION_TYPE"]
            missing = [c for c in req if c not in df.columns]
            if missing:
                return jsonify({"error": f"Missing required columns in Excel: {', '.join(missing)}"}), status.HTTP_400_BAD_REQUEST

            df = df.replace({pd.NA: "", None: ""}).fillna("")
            rows = df.to_dict(orient="records")

        else:
            body = request.get_json(force=True, silent=True) or {}
            rows = body if isinstance(body, list) else [body]

        if not rows:
            return jsonify({"error": "No valid rows to process."}), status.HTTP_400_BAD_REQUEST

        # --- Vectorized Market/Brand Validation ---
        all_markets = {r.get("MARKET", "").strip().upper() for r in rows if r.get("MARKET")}
        all_brands = {r.get("BRAND", "").strip().upper() for r in rows if r.get("BRAND")}

        valid_market_set = {m.upper() for m in valid_markets_brands.get("markets", [])}
        valid_brand_set = {b.upper() for b in valid_markets_brands.get("brands", [])}

        invalid_markets = [{"MARKET": m, "reason": "Invalid MARKET"} for m in all_markets if m not in valid_market_set]
        invalid_brands = [{"BRAND": b, "reason": "Invalid BRAND"} for b in all_brands if b not in valid_brand_set]

        if invalid_markets or invalid_brands:
            return jsonify({
                "status": "error",
                "invalid_markets": invalid_markets,
                "invalid_brands": invalid_brands
            }), status.HTTP_400_BAD_REQUEST

        # --- Batch Duplicate Check (optimize DB roundtrips) ---
        check_values = []
        for r in rows:
            check_values.append(f"('{r.get('MARKET','').upper()}', '{r.get('BRAND','').upper()}', '{r.get('COMPETITOR_BRANDS','').upper()}', '{r.get('COMPETITION_TYPE','').upper()}')")

        check_query = f"""
            SELECT MARKET, BRAND, COMPETITOR_BRANDS, COMPETITION_TYPE
            FROM hive_metastore.{os.environ['schema']}.d_ffn_competitor_config
            WHERE (MARKET, BRAND, COMPETITOR_BRANDS, COMPETITION_TYPE) IN ({','.join(check_values)})
        """
        existing = dc.execute_query(check_query)
        existing_set = {
            (r.MARKET.upper(), r.BRAND.upper(), r.COMPETITOR_BRANDS.upper(), r.COMPETITION_TYPE.upper())
            for _, r in existing.iterrows()
        }

        inserted, duplicates, errors = [], [], []
        batch_inserts = []

        for idx, r in enumerate(rows, start=1):
            try:
                market = _clean(r.get("MARKET", "")).upper()
                brand = _clean(r.get("BRAND", "")).upper()
                cbrand = _clean(r.get("COMPETITOR_BRANDS", "")).upper()
                ctype = _clean(r.get("COMPETITION_TYPE", "")).upper()

                # Mandatory field check
                if not all([market, brand, cbrand, ctype, r.get("DISEASE_STATE"), r.get("DRUG_CLASS")]):
                    raise ValueError(f"Row {idx}: Missing required fields.")

                if (market, brand, cbrand, ctype) in existing_set:
                    duplicates.append({"row": idx, "MARKET": market, "BRAND": brand, "COMPETITOR_BRANDS": cbrand, "COMPETITION_TYPE": ctype})
                    continue

                batch_inserts.append(f"""
                    ('{market}', '{brand}', '{r.get("DISEASE_STATE","")}', '{r.get("DRUG_CLASS","")}',
                     '{cbrand}', '{ctype}', '{r.get("MOLECULE","")}', '{r.get("OTHER_NAMES","")}',
                     '{r.get("COMBINATION","")}', '{added_by}', CURRENT_TIMESTAMP())
                """)

                inserted.append({"row": idx, "MARKET": market, "BRAND": brand})

            except Exception as e:
                errors.append({"row": idx, "error": str(e)})

        # --- Batch Insert (fast) ---
        if batch_inserts:
            insert_query = f"""
                INSERT INTO hive_metastore.{os.environ['schema']}.d_ffn_competitor_config
                (MARKET, BRAND, DISEASE_STATE, DRUG_CLASS, COMPETITOR_BRANDS,
                 COMPETITION_TYPE, MOLECULE, OTHER_NAMES, COMBINATION, ADDED_BY, ENTRY_TIME)
                VALUES {','.join(batch_inserts)}
            """
            dc.execute_non_query(insert_query)

        # Pagination for response summary
        total_rows = len(rows)
        total_pages = math.ceil(total_rows / limit)
        start, end = offset, offset + limit
        paginated_rows = rows[start:end]

        response = {
            "status": "success" if inserted else ("partial" if errors else "no-change"),
            "page": page,
            "limit": limit,
            "total_rows": total_rows,
            "total_pages": total_pages,
            "processed_rows": len(paginated_rows),
            "inserted_count": len(inserted),
            "duplicate_count": len(duplicates),
            "inserted_rows": inserted[start:end],
            "duplicates": duplicates[start:end],
            "errors": errors[start:end],
        }

        return jsonify(response), status.HTTP_201_CREATED if inserted else status.HTTP_200_OK

    except Exception as e:
        import traceback
        print("ERROR:", traceback.format_exc())
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR
