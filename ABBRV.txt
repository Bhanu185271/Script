# ============================================================================
# ENDPOINT 5: BRAND ACRONYMS
# ============================================================================

import json

# Only map Market and Brand - Term and Definition are used to build JSON for VALUE_1
EXCEL_TO_DB_MAPPING_ABBRV = {
    "Market": "MARKET",
    "Brand": "BRAND"
}

FIXED_INSIGHT_VALUE_ABBRV = "medical-word-reassignment"
FIXED_TYPE_VALUE_ABBRV = "ABBRV"
TARGET_SHEET_NAME_ABBRV = "Brand - Acronyms"
HEADER_ROW_INDEX_ABBRV = 2

def _batch_check_duplicates_abbrv(rows):
    """Batch duplicate check for Brand Acronyms endpoint"""
    if not rows:
        return set()
    
    duplicate_set = set()
    chunk_size = 25
    
    for chunk_start in range(0, len(rows), chunk_size):
        chunk_rows = rows[chunk_start:chunk_start + chunk_size]
        conditions = []
        
        for r in chunk_rows:
            market = _sq(r["MARKET"].upper())
            brand = _sq(r["BRAND"].upper())
            insight = _sq(r["INSIGHT"])
            type_val = _sq(r["TYPE"])
            value_1 = _sq(r["VALUE_1"])
            
            conditions.append(
                f"(UPPER(TRIM(MARKET)) = '{market}' AND "
                f"UPPER(TRIM(BRAND)) = '{brand}' AND "
                f"TRIM(INSIGHT) = '{insight}' AND "
                f"TRIM(TYPE) = '{type_val}' AND "
                f"TRIM(VALUE_1) = '{value_1}')"
            )
        
        sql = f"""
            SELECT UPPER(TRIM(MARKET)) as MARKET,
                   UPPER(TRIM(BRAND)) as BRAND,
                   TRIM(INSIGHT) as INSIGHT,
                   TRIM(TYPE) as TYPE,
                   TRIM(VALUE_1) as VALUE_1
            FROM {INSIGHT_TABLE}
            WHERE {' OR '.join(conditions)}
        """
        
        try:
            df = dc.execute_query(sql)
            if df is not None and not df.empty:
                for _, row in df.iterrows():
                    duplicate_set.add((
                        row['MARKET'], 
                        row['BRAND'], 
                        row['INSIGHT'],
                        row['TYPE'],
                        row['VALUE_1']
                    ))
        except Exception as e:
            print(f"Batch duplicate check error (chunk {chunk_start//chunk_size + 1}): {str(e)}")
    
    return duplicate_set

def _batch_insert_rows_abbrv(rows, added_by):
    """Batch insert for Brand Acronyms endpoint"""
    if not rows:
        return 0
    
    total_inserted = 0
    chunk_size = 25
    
    for chunk_start in range(0, len(rows), chunk_size):
        chunk_rows = rows[chunk_start:chunk_start + chunk_size]
        
        for r in chunk_rows:
            market_upper = r['MARKET'].upper()
            brand_upper = r['BRAND'].upper()
            
            sql = f"""
                INSERT INTO {INSIGHT_TABLE}
                    (BRAND, MARKET, INSIGHT, TYPE, VALUE_1, VALUE_2, VALUE_3, VALUE_4, ADDED_BY, ENTRY_TIME)
                VALUES
                    ('{_sq(brand_upper)}', '{_sq(market_upper)}', '{_sq(r['INSIGHT'])}', '{_sq(r['TYPE'])}',
                     '{_sq(r['VALUE_1'])}', NULL, NULL, NULL,
                     '{_sq(added_by)}', CURRENT_TIMESTAMP())
            """
            
            try:
                dc.execute_non_query(sql)
                total_inserted += 1
            except Exception as e:
                print(f"Insert error: {str(e)}")
                raise
    
    return total_inserted

def _process_template_excel_abbrv(file_obj):
    """Process Excel template for Brand Acronyms endpoint"""
    try:
        excel_file = pd.ExcelFile(file_obj, engine="openpyxl")
        
        if TARGET_SHEET_NAME_ABBRV not in excel_file.sheet_names:
            raise ValueError(
                f"Required sheet '{TARGET_SHEET_NAME_ABBRV}' not found. "
                f"Available sheets: {', '.join(excel_file.sheet_names)}"
            )
        
        df = pd.read_excel(
            file_obj, 
            sheet_name=TARGET_SHEET_NAME_ABBRV,
            header=HEADER_ROW_INDEX_ABBRV,
            engine="openpyxl"
        )
        
        if len(df.columns) > 0:
            df = df.iloc[:, 1:]
        
        df.columns = [str(c).strip() for c in df.columns]
        df = df.replace({pd.NA: "", None: ""}).fillna("")
        
        df['_excel_row_num'] = range(4, 4 + len(df))
        df = df[df.drop('_excel_row_num', axis=1).astype(str).apply(lambda x: x.str.strip().str.len().sum(), axis=1) > 0]
        
        # Check for required Excel columns
        mandatory_excel_cols = ["Market", "Brand", "Term", "Definition"]
        missing_mandatory = [col for col in mandatory_excel_cols if col not in df.columns]
        
        if missing_mandatory:
            raise ValueError(
                f"Missing mandatory columns in '{TARGET_SHEET_NAME_ABBRV}' sheet: {', '.join(missing_mandatory)}. "
                f"Found columns: {list(df.columns)}"
            )
        
        mapped_data = []
        
        for idx, row in df.iterrows():
            excel_row_num = int(row['_excel_row_num'])
            
            # Map only Market and Brand from Excel to DB columns
            market_value = _clean(row.get("Market", ""))
            brand_value = _clean(row.get("Brand", ""))
            
            # Read Term and Definition to build JSON for VALUE_1
            term_value = _clean(row.get("Term", ""))
            definition_value = _clean(row.get("Definition", ""))
            
            # Create JSON format for VALUE_1 - json.dumps automatically adds double quotes
            value_1_json = json.dumps({
                "term": term_value,
                "definition": definition_value
            })
            
            mapped_row = {
                "MARKET": market_value,
                "BRAND": brand_value,
                "VALUE_1": value_1_json,
                "INSIGHT": FIXED_INSIGHT_VALUE_ABBRV,
                "TYPE": FIXED_TYPE_VALUE_ABBRV,
                "VALUE_2": None,
                "VALUE_3": None,
                "VALUE_4": None
            }
            
            # Validate - all 4 mandatory fields must have values
            if market_value and brand_value and term_value and definition_value:
                mapped_data.append((excel_row_num, mapped_row))
        
        if not mapped_data:
            raise ValueError(
                f"No valid data rows found in sheet '{TARGET_SHEET_NAME_ABBRV}'. "
                f"Ensure mandatory fields (Market, Brand, Term, Definition) have values."
            )
        
        return mapped_data, None
        
    except Exception as e:
        raise Exception(f"Error processing template Excel: {str(e)}")

@app.route("/d_ffn_insight_config_abbrv", methods=["GET"])
def insight_abbrv_get():
    try:
        definitions = {
            "Description": {
                "BRAND": {
                    "Example Values": ["AREXVY", "SHINGRIX"],
                    "Description": "Name of Brand to be deployed",
                    "Parameter_type": "Mandatory"
                },
                "MARKET": {
                    "Example Values": ["GBR", "THA", "ITA", "PRT"],
                    "Description": "Name of the Market to be deployed",
                    "Parameter_type": "Mandatory"
                },
                "INSIGHT": {
                    "Example Values": ["medical-word-reassignment"],
                    "Description": "Fixed value for insight type",
                    "Parameter_type": "Auto-filled (Fixed Value)"
                },
                "TYPE": {
                    "Example Values": ["ABBRV"],
                    "Description": "Fixed value for type",
                    "Parameter_type": "Auto-filled (Fixed Value)"
                },
                "VALUE_1": {
                    "Example Values": ["{\"term\":\"RSV\", \"definition\":\"Respiratory Syncytial Virus\"}"],
                    "Description": "JSON format with term and definition",
                    "Parameter_type": "Mandatory"
                },
                "VALUE_2": {
                    "Example Values": ["NULL"],
                    "Description": "Reserved for future use",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "VALUE_3": {
                    "Example Values": ["NULL"],
                    "Description": "Reserved for future use",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "VALUE_4": {
                    "Example Values": ["NULL"],
                    "Description": "Reserved for future use",
                    "Parameter_type": "Auto-filled (NULL)"
                },
                "ADDED_BY": {
                    "Example Values": ["abc.x.abc@gsk.com"],
                    "Description": "Auto-picked from 'Username' header in POST",
                    "Parameter_type": "Mandatory (via header)"
                },
                "ENTRY_TIME": {
                    "Example Values": ["current_timestamp()"],
                    "Description": "Set by system at insert time",
                    "Parameter_type": "Auto-generated"
                }
            },
            "sample_json": {
                "MARKET": "THA",
                "BRAND": "AREXVY",
                "VALUE_1": "{\"term\":\"RSV\", \"definition\":\"Respiratory Syncytial Virus\"}"
            },
            "excel_upload_instructions": {
                "expected_extension": ".xlsx",
                "template_sheet_name": TARGET_SHEET_NAME_ABBRV,
                "header_row": HEADER_ROW_INDEX_ABBRV + 1,
                "form_field_name": "file",
                "required_columns": ["Market", "Brand", "Term", "Definition"],
                "column_mapping": EXCEL_TO_DB_MAPPING_ABBRV,
                "fixed_values": {
                    "INSIGHT": FIXED_INSIGHT_VALUE_ABBRV,
                    "TYPE": FIXED_TYPE_VALUE_ABBRV,
                    "VALUE_2": "NULL",
                    "VALUE_3": "NULL",
                    "VALUE_4": "NULL"
                },
                "notes": [
                    "Tablename: hive_metastore.fieldforce_navigator_deployment.d_ffn_insight_config",
                    f"The Excel file must contain a sheet named '{TARGET_SHEET_NAME_ABBRV}'",
                    f"Headers must be in row {HEADER_ROW_INDEX_ABBRV + 1} of the sheet, starting from Column B",
                    "Data rows should start from row 4 onwards, Column B onwards",
                    "Column A is ignored during processing",
                    "INSIGHT and TYPE are automatically set to fixed values",
                    "VALUE_1 is constructed as JSON from Term and Definition columns",
                    "VALUE_2, VALUE_3, VALUE_4 are automatically set to NULL"
                ]
            }
        }
        return jsonify(definitions), status.HTTP_200_OK
    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR

@app.route("/d_ffn_insight_config_abbrv", methods=["POST"])
def insight_abbrv_post():
    try:
        added_by = _clean(request.headers.get("Username", "") or "")
        if not added_by:
            return jsonify({"error": "Missing 'Username' in headers."}), status.HTTP_400_BAD_REQUEST

        _get_valid_markets_brands(force_refresh=True)

        rows = []
        is_excel_mode = False
        missing_columns_warning = None

        if "file" in request.files:
            is_excel_mode = True
            f = request.files["file"]
            fname = (f.filename or "").lower().strip()
            
            if not fname.endswith(".xlsx"):
                return jsonify({
                    "error": "Only .xlsx files are supported for bulk upload."
                }), status.HTTP_400_BAD_REQUEST

            try:
                rows, missing_columns_warning = _process_template_excel_abbrv(f)
                
                if not rows:
                    return jsonify({
                        "error": f"No valid data rows found in sheet '{TARGET_SHEET_NAME_ABBRV}'."
                    }), status.HTTP_400_BAD_REQUEST
                
            except ValueError as ve:
                return jsonify({"error": str(ve)}), status.HTTP_400_BAD_REQUEST
            except Exception as e:
                return jsonify({
                    "error": f"Failed to process Excel template: {str(e)}"
                }), status.HTTP_400_BAD_REQUEST

        else:
            body = request.get_json(force=True, silent=True) or {}
            items = body if isinstance(body, list) else [body]

            for i, rec in enumerate(items, start=1):
                market = _clean(rec.get("MARKET", ""))
                brand  = _clean(rec.get("BRAND", ""))
                value_1 = _clean(rec.get("VALUE_1", ""))

                if not market or not brand or not value_1:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Missing required field(s). MARKET, BRAND, and VALUE_1 are mandatory."
                    }), status.HTTP_400_BAD_REQUEST

                market_valid, brand_valid = _validate_market_brand_separately(market, brand)
                
                if not market_valid:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Invalid MARKET '{market}'. This market does not exist."
                    }), status.HTTP_400_BAD_REQUEST
                
                if not brand_valid:
                    return jsonify({
                        "status": "error",
                        "message": f"Item {i}: Invalid BRAND '{brand}'. This brand does not exist."
                    }), status.HTTP_400_BAD_REQUEST

                rows.append((i, {
                    "MARKET": market,
                    "BRAND": brand,
                    "INSIGHT": FIXED_INSIGHT_VALUE_ABBRV,
                    "TYPE": FIXED_TYPE_VALUE_ABBRV,
                    "VALUE_1": value_1,
                    "VALUE_2": None,
                    "VALUE_3": None,
                    "VALUE_4": None
                }))

        if not rows:
            return jsonify({"error": "No valid rows to process."}), status.HTTP_400_BAD_REQUEST

        invalid_markets = []
        invalid_brands = []
        valid_rows = []
        
        valid_data = _get_valid_markets_brands()
        
        for row_num, r in rows:
            market = r["MARKET"]
            brand = r["BRAND"]
            
            market_valid = market.upper().strip() in valid_data['markets']
            brand_valid = brand.upper().strip() in valid_data['brands']
            
            if not market_valid:
                invalid_markets.append({
                    "excel_row": row_num,
                    "MARKET": market,
                    "BRAND": brand,
                    "reason": "Invalid MARKET - not found in audio_market_brand_config"
                })
                continue
            
            if not brand_valid:
                invalid_brands.append({
                    "excel_row": row_num,
                    "MARKET": market,
                    "BRAND": brand,
                    "reason": "Invalid BRAND - not found in audio_market_brand_config"
                })
                continue
            
            valid_rows.append((row_num, r))
        
        duplicate_set = _batch_check_duplicates_abbrv([r for _, r in valid_rows])
        
        duplicates = []
        insertable_rows = []
        
        for row_num, r in valid_rows:
            key = (
                r["MARKET"].upper().strip(),
                r["BRAND"].upper().strip(),
                r["INSIGHT"].strip(),
                r["TYPE"].strip(),
                r["VALUE_1"].strip()
            )
            
            if key in duplicate_set:
                duplicates.append({
                    "excel_row": row_num,
                    "MARKET": r["MARKET"],
                    "BRAND": r["BRAND"],
                    "VALUE_1": r["VALUE_1"],
                    "reason": "Duplicate - already exists in database"
                })
            else:
                insertable_rows.append(r)
        
        inserted = 0
        errors = []
        
        if insertable_rows:
            try:
                inserted = _batch_insert_rows_abbrv(insertable_rows, added_by)
            except Exception as e:
                errors.append({
                    "error": f"Batch insert failed: {str(e)}"
                })

        response = {
            "status": "success" if inserted and not errors else ("partial" if inserted else "no-change"),
            "mode": "excel-template" if is_excel_mode else "json",
            "sheet_processed": TARGET_SHEET_NAME_ABBRV if is_excel_mode else None,
            "total_rows_processed": len(rows),
            "inserted_count": inserted,
            "duplicate_count": len(duplicates),
            "validation_errors_count": len(invalid_markets) + len(invalid_brands),
            "skipped_duplicates": duplicates,
            "invalid_markets": invalid_markets,
            "invalid_brands": invalid_brands,
            "row_errors": errors
        }
        
        if is_excel_mode and missing_columns_warning:
            response["warning"] = {
                "message": "The uploaded Excel template is missing some required columns.",
                "missing_columns": missing_columns_warning,
                "note": "All four columns (Market, Brand, Term, Definition) are required for Insight Config."
            }
        
        response = {k: v for k, v in response.items() 
                   if v is not None and not (isinstance(v, list) and len(v) == 0)}
        
        if inserted > 0:
            status_code = status.HTTP_201_CREATED
        elif invalid_markets or invalid_brands:
            status_code = status.HTTP_207_MULTI_STATUS
        else:
            status_code = status.HTTP_200_OK
        
        return jsonify(response), status_code

    except Exception as e:
        return jsonify({"error": f"Internal server error: {str(e)}"}), status.HTTP_500_INTERNAL_SERVER_ERROR
